---
title: "Untitled"
author: "Ender Alexandru, Laura Fetz, Jessee Moomey"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
# Loading packages
library(cowplot)
library(plotly)
library(gridExtra)
library(tidyverse)
library(devtools)
library(oefenwebDatabase)
library(oefenwebTools)
library(lme4)
library(lmerTest)
library(lubridate)
library(DBI)
library(ggalluvial)
# Establishing connection with oefenweb
con <- oefenwebDatabase::connect()
```

Grab the data from original database

```{r}
# Create necessary objects
ed_logs <- list()
domains <- c(1:5, 7, 9, 10, 11, 59)
change_date <- as.Date("2024-10-25")
start_date <- as.Date("2023-09-01")

# Loop through each E_D table
for (i in 1:10) {
  # Write SQL query to get data, and convert to seconds
  query <- paste0("SELECT *
                   FROM extended_deadline_logs_", domains[i])
  # Get the data and store it in the list
  ed_logs[[i]] <- suppressWarnings(DBI::dbGetQuery(con, query))
}

# Turn the list into a single df
ed_logs <- bind_rows(ed_logs)

# Getting deadlines for items in 59
query <- paste0("SELECT id AS item_id,
                 maximum_response_in_seconds AS deadline
                 FROM extended_deadline_items
                 WHERE domain_id = 59")
  # Get the data and store it in the list
deadlines_59 <- suppressWarnings(DBI::dbGetQuery(con, query))

# Convert created to date and into POSIXct format
ed_logs <- ed_logs %>%
  rename(date = created) 
ed_logs$date <-
  as.POSIXct(ed_logs$date, format = "%Y-%m-%d %H:%M:%S")
```


Ender: analyzing growth slopes in the first 2 months of 2024 (Sep-Oct 25) to growth slopes after the change (Oct 25 - Dec)

```{r}
### Checking amount of items played in the two periods, per domain ###

items_played <- ed_logs %>%
  mutate(period = case_when(
    date > "2024-09-01 00:00:01" & date < "2024-10-25 00:00:01" ~ "Sep-Oct",
    date > "2024-10-25 23:59:59" ~ "Oct-Dec",
    TRUE ~ "other")) %>%
  group_by(domain_id, period) %>%
  summarize(items_played = n()) %>%
  filter(period != "other") %>%
  arrange(domain_id, desc(period))

items_played %>%
  ggplot(aes(x = domain_id, y = items_played, fill = period)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Items Played by Domain and Period", x = "Domain", y = "Items Played")
```

Data structuring for multilevel analysis

```{r}
# Create period variable
period_logs <- ed_logs %>%
  mutate(period = case_when(
    date > "2024-09-01 00:00:01" & date < "2024-10-25 00:00:01" ~ "Sep-Oct",
    date > "2024-10-25 23:59:59" ~ "Oct-Dec",
    TRUE ~ "other")) %>%
  filter(period != "other") %>%
  filter(!is.na(new_user_domain_q_score))

# Structure data to have a Q-score for every session entry
multilevel_data <- period_logs %>%
  arrange(user_id, period, domain_id, new_user_domain_session_count, new_user_domain_modified_count) %>%
  group_by(user_id, period, domain_id, new_user_domain_session_count) %>%
  summarize(q_score = last(new_user_domain_q_score), .groups = "drop") %>%
  # need to re-attach grade & difficulty to data
  left_join(period_logs %>%
              select(user_id, period, grade, domain_id, difficulty, new_user_domain_session_count,
                     new_user_domain_modified_count),
            by = c("user_id", "period", "domain_id", "new_user_domain_session_count"))


# Re-number sessions to start from 1 (for each period separately)
multilevel_data_unique <- multilevel_data %>%
  distinct(user_id, period, domain_id, new_user_domain_session_count, .keep_all = TRUE) %>%
  group_by(user_id, period, domain_id) %>%
  mutate(session = row_number()) %>%
  ungroup() %>%
  select(-new_user_domain_modified_count, -new_user_domain_session_count)

# Check observation nr per grade, domain
table(multilevel_data_unique$grade)
table(multilevel_data_unique$domain_id)

# Remove data for grades 1, 2, and 9-19
multilevel_data_unique$grade <- as.integer(multilevel_data_unique$grade)
multilevel_data_unique <- multilevel_data_unique %>%
  filter(!(grade == 1) & !(grade == 2) & !(grade >= 9 & grade <= 19))

multilevel_data_unique$difficulty <- as.factor(multilevel_data_unique$difficulty)
multilevel_data_unique$period <- as.factor(multilevel_data_unique$period)
multilevel_data_unique$domain_id <- as.factor(multilevel_data_unique$domain_id)
multilevel_data_unique$grade <- as.factor(multilevel_data_unique$grade)

# Remove sessions over 20
multilevel_data_unique <- multilevel_data_unique %>%
  filter(session <= 20)

# Scale session & q_score
multilevel_data_unique <- multilevel_data_unique %>%
  mutate(session_scaled = scale(session)) %>%
  group_by(domain_id) %>%
  mutate(q_score_scaled = scale(q_score)) %>%
  ungroup()
```

```{r}
### Multilevel Analyses ###
# Models were tested sequentially; intervention_2 fits best
fixed_slopes <- lmer(
  q_score_scaled ~ 1 + session_scaled + (1 | user_id),
  REML = F, data = multilevel_data_unique
)

random_slopes <- lmer(
  q_score_scaled ~ 1 + session_scaled + (1 + session_scaled | user_id),
  REML = F, data = multilevel_data_unique
)

domain <- lmer(
  q_score_scaled ~ 1 + session_scaled + domain_id + (1 + session_scaled | user_id),
  REML = F, data = multilevel_data_unique
) # better fit than with session:domain_id

grade <- lmer(
  q_score_scaled ~ 1 + session_scaled + domain_id + grade + (1 + session_scaled | user_id),
  REML = F, data = multilevel_data_unique
) # does not converge with session:grade

difficulty <- lmer(
  q_score_scaled ~ 1 + session_scaled:difficulty + domain_id + grade + (1 + session_scaled | user_id),
  control = lmerControl(optCtrl = list(maxfun = 10000)),
  data = multilevel_data_unique
) # does not work with session*difficulty

diff_domain_grade <- lmer(
  q_score_scaled ~ 1 + session_scaled:difficulty + domain_id + grade + session_scaled:domain_id + session_scaled:grade + 
    (1 + session_scaled | user_id),
  control = lmerControl(optCtrl = list(maxfun = 10000)),
  data = multilevel_data_unique
) # best to include main effects

intervention_1 <- lmer(
  q_score_scaled ~ 1 + session_scaled*period + session_scaled:difficulty + domain_id + grade + 
    session_scaled:domain_id + session_scaled:grade + (1 + session_scaled | user_id),
  control = lmerControl(optCtrl = list(maxfun = 10000)),
  data = multilevel_data_unique
)

intervention_2 <- lmer(
  q_score_scaled ~ 1 + session_scaled*period + session_scaled:difficulty + domain_id + grade + 
    session_scaled:domain_id:period + session_scaled:grade:period + (1 + session_scaled | user_id),
  control = lmerControl(optCtrl = list(maxfun = 10000)),
  data = multilevel_data_unique
)

summary(intervention_2)
anova(intervention_1, intervention_2)

# Best model is intervention_2; results are basically the same with intervention_1
# Results show that the slope of growth is larger in the period Oct-Dec
```

```{r}
# Plotting slopes for different periods (across domains, grades, difficulties)
multilevel_data_unique$predicted_q_score <- predict(intervention_2)

# Plot difference in growth between the 2 periods (across domains, grades, difficulties)
ggplot(multilevel_data_unique, aes(x = session, y = q_score, color = period)) +
  geom_smooth(method = "lm", aes(group = period), se = FALSE, linetype = "solid") +  # Fit line for each period
  theme_minimal() +
  labs(
    title = "Relationship between Session and Q-Score by Period",
    x = "Session",
    y = "Q-Score",
    color = "Period"
  ) +
  scale_color_manual(values = c("blue", "red")) +  # Customize colors for each period
  theme(legend.position = "top")
```

```{r}
# Plots for different domains
domains <- c(1, 2, 3, 4, 5, 7, 9, 10, 11, 59)
for (i in domains){
  p <- ggplot(multilevel_data_unique[multilevel_data_unique$domain_id == i,], aes(x = session, y = q_score, color = period)) +
    geom_smooth(method = "lm", aes(group = period), se = FALSE, linetype = "solid") +  # Fit line for each period
    theme_minimal() +
    labs(
      title = paste("Relationship between Session and Q-Score by Period, Domain", i),
      x = "Session",
      y = "Q-Score",
      color = "Period"
    ) +
    scale_color_manual(values = c("blue", "red")) +  # Customize colors for each period
    theme(legend.position = "top")
  print(p)
}
```

```{r}
# Plots for different grades
grades <- c(3, 4, 5, 6, 7, 8)
for (i in grades){
  p <- ggplot(multilevel_data_unique[multilevel_data_unique$grade == i,], aes(x = session, y = q_score, color = period)) +
    geom_smooth(method = "lm", aes(group = period), se = FALSE, linetype = "solid") +  # Fit line for each period
    theme_minimal() +
    labs(
      title = paste("Relationship between Session and Q-Score by Period, Grade", i),
      x = "Session",
      y = "Q-Score",
      color = "Period"
    ) +
    scale_color_manual(values = c("blue", "red")) +  # Customize colors for each period
    theme(legend.position = "top")
  print(p)
}
```

```{r}
# Plots for all combinations of grades and domains
grades <- c(3, 4, 5, 6, 7, 8)
domains <- c(1, 2, 3, 4, 5, 7, 9, 10, 11, 59)

for (i in grades) {
  for (j in domains) {
    
    # Create the plot
    p <- ggplot(multilevel_data_unique[multilevel_data_unique$grade == i & multilevel_data_unique$domain_id == j,],
                aes(x = session, y = q_score, color = period)) +
      geom_smooth(method = "lm", aes(group = period), se = FALSE, linetype = "solid") +  # Fit line for each period
      theme_minimal() +
      labs(
        title = paste("Relationship between Session and Q-Score by Period, Grade", i, "Domain", j),
        x = "Session",
        y = "Q-Score",
        color = "Period"
      ) +
      scale_color_manual(values = c("blue", "red")) +  # Customize colors for each period
      theme(legend.position = "top")

    # Print the plot
    print(p)
  }
}
```

```{r}
##### WRONG #####
# Calculating percentages of correct answers per difficulty, between periods
difficulty_logs <- ed_logs %>%
  mutate(period = case_when(
    date > "2024-09-01 00:00:01" & date < "2024-10-25 00:00:01" ~ "Sep-Oct",
    date > "2024-10-25 23:59:59" ~ "Oct-Dec",
    TRUE ~ "other"))

difficulty_logs$correct_answered = as.integer(difficulty_logs$correct_answered)
difficulty_logs <- difficulty_logs %>%
  group_by(domain_id, difficulty) %>%
  summarize(percentage_correct = sum(correct_answered == 1) / n())
# easiest difficulty has smallest percentage correct, followed by medium, then hard
# the code here also includes data where the q_score is NA;
# but results are the same, regardless of what data you choose
```

```{r}
oefenwebDatabase::close_connection(con)
```

