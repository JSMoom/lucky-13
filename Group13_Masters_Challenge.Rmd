---
title: "Untitled"
author: "Ender Alexandru, Laura Fetz, Jessee Moomey"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
# Loading packages
library(cowplot)
library(scales)
library(plotly)
library(gridExtra)
library(tidyverse)
library(devtools)
library(oefenwebDatabase)
library(oefenwebTools)
library(lme4)
library(lmerTest)
library(lubridate)
library(DBI)
library(ggalluvial)
library(survival)
# Establishing connection with oefenweb
con <- oefenwebDatabase::connect()
```

### Data Processing

```{r}
# Create necessary objects
ed_logs <- list()
domains <- c(1:5, 7, 9, 10, 11, 59)
change_date <- as.Date("2024-10-25")
start_date <- as.Date("2023-09-01")

custom_theme <- theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    legend.position = "bottom",
    legend.title = element_text(face = "bold"),
    legend.text = element_text(size = 10),
    plot.subtitle = element_text(hjust = 0.5, face = "bold", size = 10)
  )

# Loop through each E_D table
for (i in 1:10) {
  # Write SQL query to get data, and convert to seconds
  query <- paste0("SELECT *
                   FROM extended_deadline_logs_", domains[i])
  # Get the data and store it in the list
  ed_logs[[i]] <- suppressWarnings(DBI::dbGetQuery(con, query))
}

# Turn the list into a single df
ed_logs <- bind_rows(ed_logs)

# Getting deadlines for items in 59
query <- paste0("SELECT id AS item_id,
                 maximum_response_in_seconds AS deadline
                 FROM extended_deadline_items
                 WHERE domain_id = 59")
  # Get the data and store it in the list
deadlines_59 <- suppressWarnings(DBI::dbGetQuery(con, query))

# Convert created to date and into POSIXct format
ed_logs <- ed_logs %>%
  rename(date = created) 
ed_logs$date <-
  as.POSIXct(ed_logs$date, format = "%Y-%m-%d %H:%M:%S")
```


```{r}
# Getting item deadlines for domain 59
items_5 <- deadlines_59 %>%
  filter(deadline == 5) %>%
  pull(item_id)

items_10 <- deadlines_59 %>%
  filter(deadline == 10) %>%
  pull(item_id)

items_15 <- deadlines_59 %>%
  filter(deadline == 15) %>%
  pull(item_id)

items_20 <- deadlines_59 %>%
  filter(deadline == 20) %>%
  pull(item_id)

# Categorical columns
cats <- colnames(ed_logs[,c(8:11, 14:15)])

# Adjustments to data
ed_logs = ed_logs %>%
  rename(response_in_seconds = response_in_milliseconds) %>%
  mutate(deadline = case_when(
    domain_id %in% c(1:4, 7, 10) ~ 20,
    domain_id == 9 ~ 30,
    domain_id == 11 ~ 60,
    domain_id == 5 ~ 8,
    domain_id == 59 & item_id %in% items_5 ~ 5,
    domain_id == 59 & item_id %in% items_10 ~ 10,
    domain_id == 59 & item_id %in% items_15 ~ 15,
    domain_id == 59 & item_id %in% items_20 ~ 20),
    response_in_seconds = response_in_seconds / 1000,
    across(all_of(cats), as.factor)
  ) 
# Adding time_weeks column and organizing by user_id then date
ed_logs <- ed_logs %>%
  group_by(user_id) %>%
  arrange(user_id, date) %>%
  mutate(time_weeks = ceiling(as.numeric(
    difftime(date, start_date, units = "weeks")
  ))) %>%
  mutate(time_weeks = ifelse(time_weeks < 1, 1, time_weeks),
         late_response = ifelse(response_in_seconds > deadline, 1, 0)) %>%  # Ensure any negative or 0 values are set to 1
  ungroup() 

```





### DESCRIPTIVES & ENGAGEMENT

```{r}
# Check the structure and unique values in domain_id
str(ed_logs)
unique(ed_logs$domain_id)

# Add a new variable indicating whether the response was late
# late_response: 1 indicates late response, 0 indicates on-time response
ed_logs <- ed_logs %>%
  mutate(late_response = ifelse(response_in_seconds > deadline, 1, 0))

# Show the earliest and latest date in the dataset
earliest_date <- min(ed_logs$date, na.rm = TRUE)
latest_date <- max(ed_logs$date, na.rm = TRUE)
print(paste("Earliest date:", earliest_date))
print(paste("Latest date:", latest_date))

# Split the data into before and after October 25, 2024
split_date <- as.Date("2024-10-25")
# Filter records after the split date
ed_logs_after <- ed_logs %>%
  filter(date > split_date)

## Data Preparation
data <- ed_logs %>%
  mutate(grade = as.numeric(as.character(grade))) %>%  # Convert grade from factor to numeric
  filter(grade >= 3 & grade <= 8)  # Keep only grades between 3 and 8

# Define the range
start_date <- as.Date("2024-09-05")
end_date <- as.Date("2024-12-14")

# Filter the data
data <- subset(data, date >= start_date & date <= end_date)

# Add the 'help' column
data$help <- ifelse(data$answer == "¿", 1, 0)

# Add the 'no_answer' column
data$no_answer <- ifelse(data$answer == "…", 1, 0)

data$learning_goal <- ifelse(data$session == "learning_goal", 1, 0)

# Function to calculate the mode
calculate_mode <- function(x) {
  unique_x <- unique(x)
  unique_x[which.max(tabulate(match(x, unique_x)))]
}

# Add a column for mode of difficulty based on user_id
data <- data %>%
  group_by(user_id) %>%
  mutate(modeDifficulty = calculate_mode(difficulty)) %>%
  ungroup()

# Define the reference date
reference_date <- as.Date("2024-10-25")

# Add the 'new_UI' column
data$new_UI <- factor(ifelse(data$date > reference_date, "After", "Before"), 
                      levels = c("Before", "After"))


# Map domain IDs to domain names
domain_names <- c(
  "1" = "Addition",
  "2" = "Subtraction",
  "3" = "Multiplication",
  "4" = "Division",
  "5" = "Mix",
  "7" = "Counting",
  "9" = "Clock",
  "10" = "Series",
  "11" = "Numerals",
  "59" = "Tables"
)

data$domain_name <- domain_names[as.character(data$domain_id)]

# Define a consistent theme for all plots
custom_theme <- theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    legend.position = "bottom",
    legend.title = element_text(face = "bold"),
    legend.text = element_text(size = 10)
  )

custom_colors <- c("Before" = "#00BFC4", "After" = "#F8766D")  # Adjust colors as needed

```

## ---------------------------------------------------------------------------- No Answer - with Error bars

```{r}
plot1 <- data %>%
  group_by(new_UI, domain_name) %>%
  summarise(
    no_answer_percentage = mean(no_answer) * 100,
    sd = sd(no_answer) * 100,  
    .groups = 'drop'
  ) %>%
  ggplot(aes(y = reorder(domain_name, no_answer_percentage), x = no_answer_percentage, fill = as.factor(new_UI))) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(xmin = no_answer_percentage - sd, xmax = no_answer_percentage + sd),
                width = 0.2, position = position_dodge(0.9)) +
  scale_fill_manual(values = custom_colors) +  # Apply consistent colors
  labs(title = "   By Domain", y = "Domain", x = "  ", fill = "Update on Oct 25th") +
  custom_theme


plot2 <- data %>%
  group_by(new_UI, grade) %>%
  summarise(
    no_answer_percentage = mean(no_answer) * 100,
    sd = sd(no_answer) * 100,
    .groups = 'drop'
  ) %>%
  ggplot(aes(x = factor(grade), y = no_answer_percentage, fill = as.factor(new_UI))) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymin = no_answer_percentage - sd, ymax = no_answer_percentage + sd),
                width = 0.2, position = position_dodge(0.9)) +
  scale_fill_manual(values = custom_colors) +  # Apply consistent colors
  labs(title = "   By Grade", x = "Grade", y = "  ", fill = "Update on Oct 25th") +
  custom_theme


plot3 <- data %>%
  group_by(new_UI, modeDifficulty) %>%
  summarise(
    no_answer_percentage = mean(no_answer) * 100,
    sd = sd(no_answer) * 100,
    .groups = 'drop'
  ) %>%
  mutate(
    modeDifficultyLabel = factor(
      case_when(
        modeDifficulty == "0" ~ "Easy",
        modeDifficulty == "1" ~ "Medium",
        modeDifficulty == "2" ~ "Hard"
      ),
      levels = c("Easy", "Medium", "Hard") # Set the desired order
    )
  ) %>%
  ggplot(aes(x = modeDifficultyLabel, y = no_answer_percentage, fill = as.factor(new_UI))) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymin = no_answer_percentage - sd, ymax = no_answer_percentage + sd),
                width = 0.2, position = position_dodge(0.9)) +
  scale_fill_manual(values = custom_colors) +  # Apply consistent colors
  labs(title = "   By Mode Difficulty", x = "Mode Difficulty", y = "  ", fill = "Update on Oct 25th") +
  custom_theme


plot4 <- data %>%
  group_by(new_UI, learning_goal) %>%
  summarise(
    no_answer_percentage = mean(no_answer) * 100,
    sd = sd(no_answer) * 100,
    .groups = 'drop'
  ) %>%
  ggplot(aes(x = factor(learning_goal, labels = c("No", "Yes")), y = no_answer_percentage, fill = as.factor(new_UI))) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymin = no_answer_percentage - sd, ymax = no_answer_percentage + sd),
                width = 0.2, position = position_dodge(0.9)) +
  scale_fill_manual(values = custom_colors) +  # Apply consistent colors
  labs(title = "      For Learning Goal Sessions", x = "Learning Goal Session", y = "  ", fill = "Update on Oct 25th") +
  custom_theme


# Combine all plots into a 2x2 grid
grid.arrange(plot1, plot2, plot3, plot4, ncol = 2)
```

## ---------------------------------------------------------------------------- No Answer - without Error bars


```{r}
plot1 <- data %>%
  group_by(new_UI, domain_name) %>%
  summarise(
    no_answer_percentage = mean(no_answer) * 100,
    sd = sd(no_answer) * 100,  
    .groups = 'drop'
  ) %>%
  ggplot(aes(y = reorder(domain_name, no_answer_percentage), x = no_answer_percentage, fill = as.factor(new_UI))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = custom_colors) +  # Apply consistent colors
  labs(title = "   By Domain", y = "Domain", x = "  ", fill = "Update on Oct 25th") +
  custom_theme


plot2 <- data %>%
  group_by(new_UI, grade) %>%
  summarise(
    no_answer_percentage = mean(no_answer) * 100,
    sd = sd(no_answer) * 100,
    .groups = 'drop'
  ) %>%
  ggplot(aes(x = factor(grade), y = no_answer_percentage, fill = as.factor(new_UI))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = custom_colors) +  # Apply consistent colors
  labs(title = "   By Grade", x = "Grade", y = "  ", fill = "Update on Oct 25th") +
  custom_theme


plot3 <- data %>%
  group_by(new_UI, modeDifficulty) %>%
  summarise(
    no_answer_percentage = mean(no_answer) * 100,
    sd = sd(no_answer) * 100,
    .groups = 'drop'
  ) %>%
  mutate(
    modeDifficultyLabel = factor(
      case_when(
        modeDifficulty == "0" ~ "Easy",
        modeDifficulty == "1" ~ "Medium",
        modeDifficulty == "2" ~ "Hard"
      ),
      levels = c("Easy", "Medium", "Hard") # Set the desired order
    )
  ) %>%
  ggplot(aes(x = modeDifficultyLabel, y = no_answer_percentage, fill = as.factor(new_UI))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = custom_colors) +  # Apply consistent colors
  labs(title = "   By Mode Difficulty", x = "Mode Difficulty", y = "  ", fill = "Update on Oct 25th") +
  custom_theme


plot4 <- data %>%
  group_by(new_UI, learning_goal) %>%
  summarise(
    no_answer_percentage = mean(no_answer) * 100,
    sd = sd(no_answer) * 100,
    .groups = 'drop'
  ) %>%
  ggplot(aes(x = factor(learning_goal, labels = c("No", "Yes")), y = no_answer_percentage, fill = as.factor(new_UI))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = custom_colors) +  # Apply consistent colors
  labs(title = "      For Learning Goal Sessions", x = "Learning Goal Session", y = "  ", fill = "Update on Oct 25th") +
  custom_theme


# Combine all plots into a 2x2 grid
grid.arrange(plot1, plot2, plot3, plot4, ncol = 2)
```

## ------------------------------------------------------------------ Statistical testss

```{r}
group_summary <- data %>%
  group_by(new_UI) %>%
  summarise(
    mean_no_answer = mean(no_answer, na.rm = TRUE),
    sd_no_answer = sd(no_answer, na.rm = TRUE),
    n = n()
  )
# Prepare the data
test_data <- data %>%
  group_by(new_UI, user_id) %>%  # Assuming individual-level responses
  summarise(
    no_answer_mean = mean(no_answer, na.rm = TRUE)  # Mean no_answer per student
  ) %>%
  ungroup()

# Perform an independent t-test
t_test_result <- t.test(
  no_answer_mean ~ new_UI,  # Compare "Before" vs "After"
  data = test_data,
  var.equal = FALSE  # Use Welch's t-test (default), which is robust to unequal variances
)

# Output the results
cat("T-Test Results:\n")
print(t_test_result)

# Define a function to perform t-tests within subgroups
perform_subgroup_t_test <- function(data, subgroup_var) {
  data %>%
    group_by(!!sym(subgroup_var)) %>%  # Group by the subgroup variable
    summarise(
      t_test_result = list(t.test(no_answer ~ new_UI, data = cur_data(), var.equal = FALSE)),
      .groups = "drop"
    ) %>%
    mutate(
      subgroup = !!sym(subgroup_var),
      t_statistic = map_dbl(t_test_result, ~ .x$statistic),
      p_value = map_dbl(t_test_result, ~ .x$p.value),
      mean_diff = map_dbl(t_test_result, ~ diff(.x$estimate)),
      conf_low = map_dbl(t_test_result, ~ .x$conf.int[1]),
      conf_high = map_dbl(t_test_result, ~ .x$conf.int[2])
    ) %>%
    select(subgroup, t_statistic, p_value, mean_diff, conf_low, conf_high)
}

# Apply the function for each subgroup variable
results_by_domain <- perform_subgroup_t_test(data, "domain_id")
results_by_grade <- perform_subgroup_t_test(data, "grade")
results_by_difficulty <- perform_subgroup_t_test(data, "modeDifficulty")
results_by_learning_goal <- perform_subgroup_t_test(data, "learning_goal")

# Display results
results_by_domain
results_by_grade
results_by_difficulty
results_by_learning_goal
```

# ---------------------------------------------------------------------------- Help - with Error Bars


```{r}
plot1 <- data %>%
  group_by(new_UI, domain_name) %>%
  summarise(
    help_percentage = mean(help) * 100,
    sd = sd(help) * 100,  
    .groups = 'drop'
  ) %>%
  ggplot(aes(y = reorder(domain_name, help_percentage), x = help_percentage, fill = as.factor(new_UI))) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(xmin = help_percentage - sd, xmax = help_percentage + sd),
                width = 0.2, position = position_dodge(0.9)) +
  scale_fill_manual(values = custom_colors) +  # Apply consistent colors
  labs(title = "  By Domain", y = "Domain", x = " ", fill = "Update on Oct 25th") +
  custom_theme


plot2 <- data %>%
  group_by(new_UI, grade) %>%
  summarise(
    help_percentage = mean(help) * 100,
    sd = sd(help) * 100,
    .groups = 'drop'
  ) %>%
  ggplot(aes(x = factor(grade), y = help_percentage, fill = as.factor(new_UI))) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymin = help_percentage - sd, ymax = help_percentage + sd),
                width = 0.2, position = position_dodge(0.9)) +
  scale_fill_manual(values = custom_colors) +  # Apply consistent colors
  labs(title = "  By Grade", x = "Grade", y = " ", fill = "Update on Oct 25th") +
  custom_theme


plot3 <- data %>%
  group_by(new_UI, modeDifficulty) %>%
  summarise(
    help_percentage = mean(help) * 100,
    sd = sd(help) * 100,
    .groups = 'drop'
  ) %>%
  mutate(
    modeDifficultyLabel = factor(
      case_when(
        modeDifficulty == "0" ~ "Easy",
        modeDifficulty == "1" ~ "Medium",
        modeDifficulty == "2" ~ "Hard"
      ),
      levels = c("Easy", "Medium", "Hard") # Set the desired order
    )
  ) %>%
  ggplot(aes(x = modeDifficultyLabel, y = help_percentage, fill = as.factor(new_UI))) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymin = help_percentage - sd, ymax = help_percentage + sd),
                width = 0.2, position = position_dodge(0.9)) +
  scale_fill_manual(values = custom_colors) +  # Apply consistent colors
  labs(title = "  By Mode Difficulty", x = "Mode Difficulty", y = " ", fill = "Update on Oct 25th") +
  custom_theme


plot4 <- data %>%
  group_by(new_UI, learning_goal) %>%
  summarise(
    help_percentage = mean(help) * 100,
    sd = sd(help) * 100,
    .groups = 'drop'
  ) %>%
  ggplot(aes(x = factor(learning_goal, labels = c("No", "Yes")), y = help_percentage, fill = as.factor(new_UI))) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymin = help_percentage - sd, ymax = help_percentage + sd),
                width = 0.2, position = position_dodge(0.9)) +
  scale_fill_manual(values = custom_colors) +  # Apply consistent colors
  labs(title = "     For Learning Goal Sessions", x = "Learning Goal Session", y = " ", fill = "Update on Oct 25th") +
  custom_theme


# Combine all plots into a 2x2 grid
grid.arrange(plot1, plot2, plot3, plot4, ncol = 2)
```

# ---------------------------------------------------------------------------- Help - without Error Bars


```{r}
plot1 <- data %>%
  group_by(new_UI, domain_name) %>%
  summarise(
    help_percentage = mean(help) * 100,
    sd = sd(help) * 100,  
    .groups = 'drop'
  ) %>%
  ggplot(aes(y = reorder(domain_name, help_percentage), x = help_percentage, fill = as.factor(new_UI))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = custom_colors) +  # Apply consistent colors
  labs(title = "  By Domain", y = "Domain", x = " ", fill = "Update on Oct 25th") +
  custom_theme


plot2 <- data %>%
  group_by(new_UI, grade) %>%
  summarise(
    help_percentage = mean(help) * 100,
    sd = sd(help) * 100,
    .groups = 'drop'
  ) %>%
  ggplot(aes(x = factor(grade), y = help_percentage, fill = as.factor(new_UI))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = custom_colors) +  # Apply consistent colors
  labs(title = "  By Grade", x = "Grade", y = " ", fill = "Update on Oct 25th") +
  custom_theme


plot3 <- data %>%
  group_by(new_UI, modeDifficulty) %>%
  summarise(
    help_percentage = mean(help) * 100,
    sd = sd(help) * 100,
    .groups = 'drop'
  ) %>%
  mutate(
    modeDifficultyLabel = factor(
      case_when(
        modeDifficulty == "0" ~ "Easy",
        modeDifficulty == "1" ~ "Medium",
        modeDifficulty == "2" ~ "Hard"
      ),
      levels = c("Easy", "Medium", "Hard") # Set the desired order
    )
  ) %>%
  ggplot(aes(x = modeDifficultyLabel, y = help_percentage, fill = as.factor(new_UI))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = custom_colors) +  # Apply consistent colors
  labs(title = "  By Mode Difficulty", x = "Mode Difficulty", y = " ", fill = "Update on Oct 25th") +
  custom_theme


plot4 <- data %>%
  group_by(new_UI, learning_goal) %>%
  summarise(
    help_percentage = mean(help) * 100,
    sd = sd(help) * 100,
    .groups = 'drop'
  ) %>%
  ggplot(aes(x = factor(learning_goal, labels = c("No", "Yes")), y = help_percentage, fill = as.factor(new_UI))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = custom_colors) +  # Apply consistent colors
  labs(title = "     For Learning Goal Sessions", x = "Learning Goal Session", y = " ", fill = "Update on Oct 25th") +
  custom_theme


# Combine all plots into a 2x2 grid
grid.arrange(plot1, plot2, plot3, plot4, ncol = 2)
```

#------------------------------------------------------------------------------ Statistical analysis


```{r}
# Summarize the data: Calculate the mean and standard deviation of "help" usage before and after the new UI
help_summary <- data %>%
  group_by(new_UI) %>%
  summarise(
    mean_help = mean(help, na.rm = TRUE),  # Average "help" usage
    sd_help = sd(help, na.rm = TRUE),      # Standard deviation of "help" usage
    n = n()                                # Sample size
  )

# Perform an independent t-test to test for differences in "help" usage
t_test_help <- t.test(
  help ~ new_UI,  # Test if "help" differs between "Before" and "After"
  data = data,
  var.equal = FALSE  # Use Welch's t-test by default
)

# Output results
cat("Summary of Help Usage by New UI:\n")
print(help_summary)
cat("\nT-Test Results:\n")
print(t_test_help)


# Define a function to perform t-tests for subgroups
perform_subgroup_t_test <- function(data, subgroup_var) {
  data %>%
    group_by(!!sym(subgroup_var)) %>%  # Group by the subgroup variable
    summarise(
      t_test_result = list(t.test(help ~ new_UI, data = cur_data(), var.equal = FALSE)),  # Perform t-test
      .groups = "drop"
    ) %>%
    mutate(
      subgroup = !!sym(subgroup_var),
      t_statistic = map_dbl(t_test_result, ~ .x$statistic),
      p_value = map_dbl(t_test_result, ~ .x$p.value),
      mean_diff = map_dbl(t_test_result, ~ diff(.x$estimate)),
      conf_low = map_dbl(t_test_result, ~ .x$conf.int[1]),
      conf_high = map_dbl(t_test_result, ~ .x$conf.int[2])
    ) %>%
    select(subgroup, t_statistic, p_value, mean_diff, conf_low, conf_high)
}

# Apply the function for each subgroup variable
results_by_domain <- perform_subgroup_t_test(data, "domain_id")
results_by_grade <- perform_subgroup_t_test(data, "grade")
results_by_difficulty <- perform_subgroup_t_test(data, "modeDifficulty")
results_by_learning_goal <- perform_subgroup_t_test(data, "learning_goal")

# Display results
results_by_domain
results_by_grade
results_by_difficulty
results_by_learning_goal
```

# ---------------------------------------------------------------------------- Percentage correct without


```{r}
correct_answers_domain <- data %>%
  group_by(new_UI, domain_id) %>%
  summarise(
    total_responses = n(),
    correct_responses = sum(correct_answered == "1"),
    correct_percentage = mean(correct_answered == "1") * 100,
    .groups = 'drop'
  ) %>%
  mutate(
    UI_Status = new_UI,  # Consistent with "Before" and "After"
    domain_name = domain_names[as.character(domain_id)]
  )

plot1 <- ggplot(correct_answers_domain, aes(x = correct_percentage, y = domain_name, fill = UI_Status)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8)) +
  scale_fill_manual(values = custom_colors) +  
  labs(title = "    By Domain", x = "   ", y = "Domain", fill = "Update on Oct 25th") +
  custom_theme

correct_answers_grade <- data %>%
  group_by(new_UI, grade) %>%
  summarise(
    total_responses = n(),
    correct_responses = sum(correct_answered == "1"),
    correct_percentage = mean(correct_answered == "1") * 100,
    .groups = 'drop'
  ) %>%
  mutate(UI_Status = new_UI)

plot2 <- ggplot(correct_answers_grade, aes(x = factor(grade), y = correct_percentage, fill = UI_Status)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8)) +
  scale_fill_manual(values = custom_colors) +  
  labs(title = "    By Grade", x = "Grade", y = "   ", fill = "Update on Oct 25th") +
  custom_theme


correct_answers_difficulty <- data %>%
  group_by(new_UI, modeDifficulty) %>%
  summarise(
    total_responses = n(),
    correct_responses = sum(correct_answered == "1"),
    correct_percentage = mean(correct_answered == "1") * 100,
    .groups = 'drop'
  ) %>%
  mutate(
    UI_Status = new_UI,
    Difficulty = factor(
      case_when(
        modeDifficulty == "0" ~ "Easy",
        modeDifficulty == "1" ~ "Medium",
        modeDifficulty == "2" ~ "Hard"
      ),
      levels = c("Easy", "Medium", "Hard")  # Set the correct order
    )
  )

plot3 <- ggplot(correct_answers_difficulty, aes(x = Difficulty, y = correct_percentage, fill = UI_Status)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8)) +
  scale_fill_manual(values = custom_colors) +  
  labs(title = "    By Difficulty", x = "Difficulty", y = "   ", fill = "Update on Oct 25th") +
  custom_theme

correct_answers_learning <- data %>%
  group_by(new_UI, learning_goal) %>%
  summarise(
    total_responses = n(),
    correct_responses = sum(correct_answered == "1"),
    correct_percentage = mean(correct_answered == "1") * 100,
    .groups = 'drop'
  ) %>%
  mutate(
    UI_Status = new_UI,
    LearningGoal = factor(ifelse(learning_goal == 1, "Yes", "No"), levels = c("No", "Yes"))
  )

plot4 <- ggplot(correct_answers_learning, aes(x = LearningGoal, y = correct_percentage, fill = UI_Status)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8)) +
  scale_fill_manual(values = custom_colors) +  
  labs(title = "    By Learning Goal", x = "Learning Goal", y = "   ", fill = "Update on Oct 25th") +
  custom_theme

grid.arrange(plot1, plot2, plot3, plot4, ncol = 2)
```

# ---------------------------------------------------------------------------- Percentage correct with


```{r}
correct_answers_domain <- data %>%
  group_by(new_UI, domain_id) %>%
  summarise(
    total_responses = n(),
    correct_responses = sum(correct_answered == "1"),
    correct_percentage = mean(correct_answered == "1") * 100,
    sd = sd(correct_answered == "1") * 100,  # Calculate SD
    .groups = 'drop'
  ) %>%
  mutate(
    UI_Status = new_UI,  
    domain_name = domain_names[as.character(domain_id)]
  )

plot1 <- ggplot(correct_answers_domain, aes(x = correct_percentage, y = domain_name, fill = UI_Status)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8)) +
  geom_errorbar(aes(xmin = correct_percentage - sd, xmax = correct_percentage + sd), 
                width = 0.2, position = position_dodge(0.8)) +
  scale_fill_manual(values = custom_colors) +  
  labs(title = "    By Domain", x = "   ", y = "Domain", fill = "Update on Oct 25th") +
  custom_theme


correct_answers_grade <- data %>%
  group_by(new_UI, grade) %>%
  summarise(
    total_responses = n(),
    correct_responses = sum(correct_answered == "1"),
    correct_percentage = mean(correct_answered == "1") * 100,
    sd = sd(correct_answered == "1") * 100,
    .groups = 'drop'
  ) %>%
  mutate(UI_Status = new_UI)

plot2 <- ggplot(correct_answers_grade, aes(x = factor(grade), y = correct_percentage, fill = UI_Status)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8)) +
  geom_errorbar(aes(ymin = correct_percentage - sd, ymax = correct_percentage + sd), 
                width = 0.2, position = position_dodge(0.8)) +
  scale_fill_manual(values = custom_colors) +  
  labs(title = "    By Grade", x = "Grade", y = "   ", fill = "Update on Oct 25th") +
  custom_theme


correct_answers_difficulty <- data %>%
  group_by(new_UI, modeDifficulty) %>%
  summarise(
    total_responses = n(),
    correct_responses = sum(correct_answered == "1"),
    correct_percentage = mean(correct_answered == "1") * 100,
    sd = sd(correct_answered == "1") * 100,
    .groups = 'drop'
  ) %>%
  mutate(
    UI_Status = new_UI,
    Difficulty = factor(
      case_when(
        modeDifficulty == "0" ~ "Easy",
        modeDifficulty == "1" ~ "Medium",
        modeDifficulty == "2" ~ "Hard"
      ),
      levels = c("Easy", "Medium", "Hard")
    )
  )

plot3 <- ggplot(correct_answers_difficulty, aes(x = Difficulty, y = correct_percentage, fill = UI_Status)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8)) +
  geom_errorbar(aes(ymin = correct_percentage - sd, ymax = correct_percentage + sd), 
                width = 0.2, position = position_dodge(0.8)) +
  scale_fill_manual(values = custom_colors) +  
  labs(title = "    By Difficulty", x = "Difficulty", y = "   ", fill = "Update on Oct 25th") +
  custom_theme


correct_answers_learning <- data %>%
  group_by(new_UI, learning_goal) %>%
  summarise(
    total_responses = n(),
    correct_responses = sum(correct_answered == "1"),
    correct_percentage = mean(correct_answered == "1") * 100,
    sd = sd(correct_answered == "1") * 100,
    .groups = 'drop'
  ) %>%
  mutate(
    UI_Status = new_UI,
    LearningGoal = factor(ifelse(learning_goal == 1, "Yes", "No"), levels = c("No", "Yes"))
  )

plot4 <- ggplot(correct_answers_learning, aes(x = LearningGoal, y = correct_percentage, fill = UI_Status)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8)) +
  geom_errorbar(aes(ymin = correct_percentage - sd, ymax = correct_percentage + sd), 
                width = 0.2, position = position_dodge(0.8)) +
  scale_fill_manual(values = custom_colors) +  
  labs(title = "    By Learning Goal", x = "Learning Goal", y = "   ", fill = "Update on Oct 25th") +
  custom_theme

grid.arrange(plot1, plot2, plot3, plot4, ncol = 2)
```

# ---------------------------------------------------------------------------- Testing significance 


```{r}
# Convert `correct_answered` to numeric
data$correct_answered <- as.numeric(as.character(data$correct_answered))

# Overall t-test for correct answers (Before vs After)
overall_t_test <- t.test(correct_answered ~ new_UI, data = data, var.equal = FALSE)

# Summarize overall mean and SD by new_UI
overall_summary <- data %>%
  group_by(new_UI) %>%
  summarise(
    mean_correct = mean(correct_answered, na.rm = TRUE) * 100,  # Mean in percentage
    sd_correct = sd(correct_answered, na.rm = TRUE) * 100,      # Standard deviation in percentage
    n = n()                                                    # Sample size
  )

# Print overall results
cat("Overall Summary:\n")
print(overall_summary)
cat("\nOverall T-Test Results:\n")
print(overall_t_test)

# Define a function to test for significance by subgroup
perform_significance_test <- function(data, group_var) {
  data %>%
    group_by(!!sym(group_var)) %>%  # Group by the specified variable
    summarise(
      t_test_result = list(t.test(correct_answered ~ new_UI, data = cur_data(), var.equal = FALSE)),
      .groups = "drop"
    ) %>%
    mutate(
      subgroup = !!sym(group_var),
      t_statistic = map_dbl(t_test_result, ~ .x$statistic),
      p_value = map_dbl(t_test_result, ~ .x$p.value),
      mean_diff = map_dbl(t_test_result, ~ diff(.x$estimate) * 100),  # Mean difference in percentage
      conf_low = map_dbl(t_test_result, ~ .x$conf.int[1] * 100),
      conf_high = map_dbl(t_test_result, ~ .x$conf.int[2] * 100)
    ) %>%
    select(subgroup, t_statistic, p_value, mean_diff, conf_low, conf_high)
}

# Test significance for each subgroup
results_by_domain <- perform_significance_test(data, "domain_id")
results_by_grade <- perform_significance_test(data, "grade")
results_by_difficulty <- perform_significance_test(data, "modeDifficulty")
results_by_learning_goal <- perform_significance_test(data, "learning_goal")

# Print subgroup results
cat("\nSignificance by Domain:\n")
print(results_by_domain)
cat("\nSignificance by Grade:\n")
print(results_by_grade)
cat("\nSignificance by Difficulty:\n")
print(results_by_difficulty)
cat("\nSignificance by Learning Goal:\n")
print(results_by_learning_goal)
```

## ----------------------------------------------------------------------------- basic overview :


```{r}
# Total items answered
items_answered <- data %>%
  group_by(new_UI) %>%
  summarise(
    total_items = n(),
    .groups = "drop"
  )
t_test_items <- t.test(item_id ~ new_UI, data = data)

# Average response time and significance test
response_time <- data %>%
  group_by(new_UI) %>%
  summarise(
    avg_response_time = mean(response_in_seconds, na.rm = TRUE),
    sd_response_time = sd(response_in_seconds, na.rm = TRUE),
    n = n(),
    .groups = "drop"
  )
t_test_response_time <- t.test(response_in_seconds ~ new_UI, data = data)

# Average daily unique users and significance test
t_test_daily_users <- t.test(
  daily_users ~ new_UI,
  data = data %>%
    group_by(new_UI, date) %>%
    summarise(daily_users = n_distinct(user_id), .groups = "drop")
)

# Average daily sessions per user and significance test
daily_sessions_per_user <- data %>%
  group_by(new_UI, date) %>%
  summarise(
    total_sessions = n(),
    unique_users = n_distinct(user_id),
    avg_sessions_per_user = total_sessions / unique_users,
    .groups = "drop"
  ) %>%
  group_by(new_UI) %>%
  summarise(
    avg_sessions_per_user = mean(avg_sessions_per_user, na.rm = TRUE),
    sd_sessions_per_user = sd(avg_sessions_per_user, na.rm = TRUE),
    n_days = n(),  # Number of days
    .groups = "drop"
  )
t_test_sessions_per_user <- t.test(
  avg_sessions_per_user ~ new_UI,
  data = data %>%
    group_by(new_UI, date) %>%
    summarise(
      total_sessions = n(),
      unique_users = n_distinct(user_id),
      avg_sessions_per_user = total_sessions / unique_users,
      .groups = "drop"
    )
)

# Combine results
descriptives <- items_answered %>%
  left_join(response_time, by = "new_UI") %>%
  left_join(daily_unique_users, by = "new_UI") %>%
  left_join(daily_sessions_per_user, by = "new_UI")

# Print the final descriptive statistics
print(descriptives)

# Print t-test results
cat("\nT-Test Results:\n")
cat("\nResponse Time:\n")
print(t_test_response_time)
cat("\nDaily Unique Users:\n")
print(t_test_daily_users)
cat("\nDaily Sessions Per User:\n")
print(t_test_sessions_per_user)
```

##------------------------------------------------------------------------------ Temporal pattern


```{r}
# Ensure `date` is in POSIXct format
data$date <- as.POSIXct(data$date)

# Add `hour` column to the data
data <- data %>%
  mutate(hour = hour(date))  # Extract hour from the date column

# Filter data for "After" the new UI and exclude rows where no_answer = 1 and late_response = 1
filtered_data <- data %>%
  filter(new_UI == "After" & !(late_response == 1 & no_answer == 1))

# Late Responses by Hour of the Day
late_response_by_hour <- filtered_data %>%
  group_by(hour) %>%
  summarize(
    total_responses = n(),
    late_responses = sum(late_response),
    late_response_rate = round(mean(late_response) * 100, 2),
    .groups = "drop"
  )

# Plot Late Response Rate by Hour
plot_hour <- late_response_by_hour %>%
  ggplot(aes(x = hour, y = late_response_rate)) +
  geom_line(color = "#57b0b5", size = 1.2) +
  geom_point(color = "#57b0b5", size = 3) +
  labs(
    title = "Late Response Rate by Hour of Day",
    x = "Hour of Day",
    y = "Late Response Rate (%)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold")
  )

# Late Responses by Weekday
plot_weekday <- ggplot(late_response_by_weekday, aes(x = weekday, y = late_response_rate)) +
  geom_bar(stat = "identity", fill = "#fe6c66") +
  labs(
    title = "Late Responses by Weekday",
    x = "Weekday",
    y = "Late Response Rate (%)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold")
  )

# Late Responses by Week Since New UI
plot_week <- ggplot(late_response_by_week, aes(x = week_since_ui, y = late_response_rate)) +
  geom_line(color = "#57b0b5", size = 1) +
  geom_point(color = "#57b0b5", size = 2) +
  labs(
    title = "Late Responses by Week",
    x = "Week Since New UI",
    y = "Late Response Rate (%)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold")
  )

# Combine all plots into a grid
grid.arrange(plot_hour, plot_weekday, plot_week, ncol = 3)
```

##------------------------------------------------------------------------------ 


```{r}
# ANOVA for Late Response Rate by Hour
anova_hour <- aov(late_response ~ as.factor(hour), data = filtered_data)
cat("ANOVA for Late Response Rate by Hour:\n")
summary(anova_hour)

# ANOVA for Late Response Rate by Weekday
anova_weekday <- aov(late_response ~ as.factor(wday(date)), data = filtered_data)
cat("\nANOVA for Late Response Rate by Weekday:\n")
summary(anova_weekday)

# Create the week_since_ui variable
filtered_data <- filtered_data %>%
  mutate(week_since_ui = floor(as.numeric(difftime(date, min(date), units = "weeks"))))


# ANOVA for Late Response Rate by Week Since New UI
anova_week <- aov(late_response ~ as.factor(week_since_ui), data = filtered_data)
cat("\nANOVA for Late Response Rate by Week Since New UI:\n")
summary(anova_week)

# Post-hoc Analysis for Late Response Rate by Hour
tukey_hour <- TukeyHSD(anova_hour)
cat("Post-hoc Analysis for Late Response Rate by Hour:\n")
print(tukey_hour)

# Post-hoc Analysis for Late Response Rate by Weekday
tukey_weekday <- TukeyHSD(anova_weekday)
cat("\nPost-hoc Analysis for Late Response Rate by Weekday:\n")
print(tukey_weekday)

# Post-hoc Analysis for Late Response Rate by Week Since New UI
tukey_week <- TukeyHSD(anova_week)
cat("\nPost-hoc Analysis for Late Response Rate by Week Since New UI:\n")
print(tukey_week)

# Calculate total responses and late responses by hour
responses_by_hour <- filtered_data %>%
  group_by(hour) %>%
  summarize(
    total_responses = n(),
    late_responses = sum(late_response),
    late_response_rate = round(mean(late_response) * 100, 2),
    .groups = "drop"
  )

# Calculate total responses and late responses by weekday
responses_by_weekday <- filtered_data %>%
  mutate(weekday = wday(date, label = TRUE)) %>%
  group_by(weekday) %>%
  summarize(
    total_responses = n(),
    late_responses = sum(late_response),
    late_response_rate = round(mean(late_response) * 100, 2),
    .groups = "drop"
  )
```

##------------------------------------------------------------------------------


```{r}
# Filter data for domain = 59
data_domain_59 <- data %>% filter(domain_id == 59)

# Calculate the percentage of late_responses that are not no_responses per deadline compared to total responses
result <- data_domain_59 %>%
  group_by(deadline) %>%
  summarise(
    total_responses = n(),  # Total number of responses
    total_late_responses = sum(late_response == TRUE),  # Total late responses
    non_no_responses = sum(late_response == TRUE & no_answer == FALSE),  # Late but not no responses
    percentage_non_no_responses = (non_no_responses / total_responses) * 100  # Percentage compared to total responses
  )

# Plot the result using ggplot
late<- ggplot(result, aes(x = as.factor(deadline), y = percentage_non_no_responses)) +
  geom_bar(stat = "identity", fill = "#fe6c66") +
  labs(
    title = "Late Responses per Deadline",
    x = "Deadline",
    y = "Percentage (%)"
  ) +
  custom_theme

# Calculate the percentage of no_answer responses before new_UI (1 vs 0) per deadline
result_no_answer <- data_domain_59 %>%
  group_by(deadline, new_UI) %>%
  summarise(
    total_responses = n(),  # Total number of responses
    total_no_answer = sum(no_answer == TRUE),  # Total no_answer responses
    percentage_no_answer = (total_no_answer / total_responses) * 100  # Percentage of no_answer
  )

# Plot the result using ggplot
no_answer_plot <- ggplot(result_no_answer, aes(x = as.factor(deadline), y = percentage_no_answer, fill = as.factor(new_UI))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = c("#00BFC4", "#fe6c66")) +  # Custom colors for new_UI 0 and 1
  labs(
    title = "No Answer per Deadline",
    x = "Deadline",
    y = "Percentage (%)",
    fill = "Update on Oc 25th "
  ) +
  custom_theme  # You can replace with your custom theme if needed

# Display the plot
print(no_answer_plot)

# Calculate the percentage of correct responses before and after the new UI (1 vs 0) per deadline
correct_answered <- data_domain_59 %>%
  group_by(deadline, new_UI) %>%
  summarise(
    total_responses = n(),  # Total number of responses
    total_correct = sum(correct_answered == 1),  # Total correct responses
    percentage_correct = (total_correct / total_responses) * 100  # Percentage of correct responses
  )

# Plot the result using ggplot
correct_plot <- ggplot(correct_answered, aes(x = as.factor(deadline), y = percentage_correct, fill = as.factor(new_UI))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = c("#00BFC4", "#fe6c66")) +  # Custom colors for new_UI 0 and 1
  labs(
    title = "Correct Responses per Deadline",
    x = "Deadline",
    y = "Percentage (%)",
    fill = "Update on Oct 25th"
  ) +
  custom_theme  # You can replace with your custom theme if needed

# print plot
print(correct_plot)

# Combine all plots into a grid
grid.arrange(no_answer_plot, late, correct_plot, ncol = 3)


# Calculate the total number of unique items (item_id) played before and after the new UI (1 vs 0) per domain
result_items_played <- data %>%
  group_by(domain_id, new_UI) %>%
  summarise(
    total_items_played = n()  # Count distinct item_id (unique items played)
  )

# Add the domain names to the result
result_items_played$domain_name <- domain_names[as.character(result_items_played$domain_id)]

# Plot the result using ggplot
items_played_plot <- ggplot(result_items_played, aes(x = domain_name, y = total_items_played, fill = as.factor(new_UI))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = c("#00BFC4", "#F8766D")) +  # Custom colors for new_UI 0 and 1
  labs(
    title = "Total Items Played per Domain",
    x = " ",
    y = "TotalItems Played",
    fill = "Update on Oct 25th"
  ) +
  custom_theme  # You can replace with your custom theme if needed

# Display the plot
print(items_played_plot)
```



```{r}
# Percent of late responses that went past extended
sum(ed_logs_after$answer == "…")/sum(ed_logs_after$late_response == 1) * 100 # 23.92%
```



### ABILITY

Multilevel analysis next: analyzing growth slopes in the first 2 months of 2024 (Sep-Oct 25) to growth slopes after the change (Oct 25 - Dec)

```{r}
### Checking amount of items played in the two periods, per domain ###
items_played <- ed_logs %>%
  mutate(period = case_when(
    date > "2024-09-01 00:00:01" & date < "2024-10-25 00:00:01" ~ "Sep-Oct",
    date > "2024-10-25 23:59:59" ~ "Oct-Dec",
    TRUE ~ "other")) %>%
  group_by(domain_id, period) %>%
  summarize(items_played = n()) %>%
  filter(period != "other") %>%
  arrange(domain_id, desc(period))

items_played$period <- factor(items_played$period, levels = c("Sep-Oct", "Oct-Dec"))

items_played %>%
  ggplot(aes(x = domain_id, y = items_played, fill = period)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Items Played by Domain and Period", x = "Domain", y = "Items Played") +
  scale_fill_manual(values = c("Sep-Oct" = "#57b0b5", "Oct-Dec"= "#fe6c66")) +
  custom_theme
```

Having similar (and sufficient) amounts of items played in the two periods across domains, we can proceed with data preparation for a multilevel analysis that investigates growth, taking into account domains, grades, usage of extended deadline


```{r}
### Structuring data for multilevel analysis
period_logs <- ed_logs %>%
  mutate(period = case_when(
    date > "2024-09-01 00:00:01" & date < "2024-10-25 00:00:01" ~ "Sep-Oct",
    date > "2024-10-25 23:59:59" ~ "Oct-Dec",
    TRUE ~ "other")) %>%
  filter(period != "other") %>%
  filter(!is.na(new_user_domain_q_score))

# Record answers as either being in the extended deadline time or not
period_logs <- period_logs %>%
  mutate(late_response = ifelse(response_in_seconds > deadline & answer != "…", 1, 0))
```

```{r}
# Structure data to have a Q-score for every session entry, prepare other variables

# Categorize users that never used, or used extended deadline above or below mean (per domain)
ext_deadline_usage <- period_logs %>%
  group_by(user_id, period, domain_id) %>%
  summarize(
    usage_extended_deadline = mean(late_response),
    never_used_deadline = all(late_response == 0), 
    .groups = "drop") %>%
  ungroup() %>%
  # Calculate the mean usage for each domain (taking into account the period)
  group_by(period, domain_id) %>%
  mutate(
    domain_avg_extended_deadline = mean(usage_extended_deadline[!never_used_deadline])
  ) %>%
  ungroup() %>%
  # Classify users based on domain-specific average
  mutate(
    extended_deadline_group = case_when(
      never_used_deadline ~ "Never",
      usage_extended_deadline > domain_avg_extended_deadline ~ "Above average",
      TRUE ~ "Below average"))

# Compute Q_score at the end of the session, and usage of extended deadline
multilevel_data <- period_logs %>%
  arrange(user_id, period, domain_id, new_user_domain_session_count, new_user_domain_modified_count) %>%
  group_by(user_id, period, domain_id, new_user_domain_session_count) %>%
  # calculate q_score at the end of the session
  summarize(q_score = last(new_user_domain_q_score),
            ext_deadline_usage = mean(late_response), .groups = "drop") %>%
  # need to re-attach grade & difficulty to data
  left_join(period_logs %>%
              select(user_id, period, grade, domain_id, difficulty, new_user_domain_session_count,
                     new_user_domain_modified_count),
            by = c("user_id", "period", "domain_id", "new_user_domain_session_count"))

# Re-number sessions to start from 1 (separate for each period, domain, and user combination)
multilevel_data_unique <- multilevel_data %>%
  distinct(user_id, period, domain_id, new_user_domain_session_count, .keep_all = TRUE) %>%
  group_by(user_id, period, domain_id) %>%
  mutate(session = row_number()) %>%
  ungroup() %>%
  select(-new_user_domain_modified_count, -new_user_domain_session_count)

# Add variable describing category of user (never used, above or below average use of extended deadline)
multilevel_data_unique <- multilevel_data_unique %>%
  left_join(
    ext_deadline_usage %>% 
      select(user_id, period, domain_id, extended_deadline_group),
    by = c("user_id", "period", "domain_id")) %>%
  mutate(extended_deadline_group = relevel(factor(extended_deadline_group), ref = "Never"))

# Check observation numbers per grade, domain
print("Number of sessions for each grade")
table(multilevel_data_unique$grade)
print("Number of sessions for each domain")
table(multilevel_data_unique$domain_id)

# Remove data for grades 1, 2, and 9-19, as there is too little data there
multilevel_data_unique$grade <- as.integer(multilevel_data_unique$grade)
multilevel_data_unique <- multilevel_data_unique %>%
  filter(!(grade == 1) & !(grade == 2) & !(grade >= 9 & grade <= 19))

# Set variables as factors
multilevel_data_unique$difficulty <- as.factor(multilevel_data_unique$difficulty)
multilevel_data_unique$period <- as.factor(multilevel_data_unique$period)
multilevel_data_unique$domain_id <- as.factor(multilevel_data_unique$domain_id)
multilevel_data_unique$grade <- as.factor(multilevel_data_unique$grade)
multilevel_data_unique$extended_deadline_group <- as.factor(multilevel_data_unique$extended_deadline_group)

# Remove sessions over 20; analysis will be done on growth across 20 sessions,
# since there is little data for users that played more than that, and it is noisy
multilevel_data_unique <- multilevel_data_unique %>%
  filter(session <= 20)

# Scale session, q_score; this fixes convergence issues in the models
# analysis results are the same with q_score scaled per domain, or across all domains
# here we scale it across all domains
multilevel_data_unique <- multilevel_data_unique %>%
  mutate(session_scaled = scale(session)) %>%
  mutate(q_score_scaled = scale(q_score)) %>%
  ungroup()

# Extract scaling parameters; will be necessary for plots
session_mean <- attr(scale(multilevel_data_unique$session), "scaled:center")
session_sd <- attr(scale(multilevel_data_unique$session), "scaled:scale")
q_score_mean <- attr(scale(multilevel_data_unique$q_score), "scaled:center")
q_score_sd <- attr(scale(multilevel_data_unique$q_score), "scaled:scale")

# For the analyses we will use multilevel_data_unique as the main data-set
```

```{r}
### T-test to check whether q_score penalty is the same, given that an answer was correct VS incorrect in the extended deadline ###
t_test_data <- period_logs[period_logs$period == "Oct-Dec",] %>%
  group_by(user_id, domain_id) %>%
  mutate(q_score_diff = new_user_domain_q_score - lag(new_user_domain_q_score)) %>%
  mutate(q_score_diff = replace(q_score_diff, is.na(q_score_diff), 0)) %>%  # replace NA with 0
  ungroup()

# group 0 = used extended deadline, responded incorrect
# group 1 = used extended deadline, responded correct
group_0 <- t_test_data$q_score_diff[t_test_data$late_response == 1 & t_test_data$correct_answered == 0]
group_1 <- t_test_data$q_score_diff[t_test_data$late_response == 1 & t_test_data$correct_answered == 1]

# T-test: do players lose the same amount of q_score if they answered correctly VS incorrectly in the extended deadline?
t_test_result <- t.test(group_0, group_1)
print(t_test_result)

# Answer: players lose about 2 more q_score points if they answer incorrectly
```

```{r}
### Multilevel Analyses ###
# Models were tested sequentially; intervention_final fits best
fixed_slopes <- lmer(
  q_score_scaled ~ 1 + session_scaled +
    (1 | user_id),
  REML = F, data = multilevel_data_unique)

random_slopes <- lmer(
  q_score_scaled ~ 1 + session_scaled +
    (1 + session_scaled | user_id),
  REML = F, data = multilevel_data_unique)

domain <- lmer(
  q_score_scaled ~ 1 + session_scaled +
    domain_id +
    (1 + session_scaled | user_id),
  REML = F, data = multilevel_data_unique)

grade <- lmer(
  q_score_scaled ~ 1 + session_scaled +
    domain_id +
    grade +
    (1 + session_scaled | user_id),
  REML = F, data = multilevel_data_unique)
# does not converge with session:grade

difficulty <- lmer(
  q_score_scaled ~ 1 + session_scaled:difficulty +
    domain_id +
    grade +
    (1 + session_scaled | user_id),
  control = lmerControl(optCtrl = list(maxfun = 10000)), # increase iterations to achieve convergence
  data = multilevel_data_unique)
# does not converge with main effect of difficulty
# this is because changes in difficulty do not reset session counter

diff_domain_grade <- lmer(
  q_score_scaled ~ 1 + session_scaled:difficulty +
    domain_id +
    grade +
    session_scaled:domain_id +
    session_scaled:grade +
    (1 + session_scaled | user_id),
  control = lmerControl(optCtrl = list(maxfun = 10000)),
  data = multilevel_data_unique)
# best to include grade & domain main effects, but also growth interactions

intervention_1 <- lmer(
  q_score_scaled ~ 1 + session_scaled*period +
    session_scaled:difficulty +
    domain_id +
    grade +
    session_scaled:domain_id +
    session_scaled:grade +
    (1 + session_scaled | user_id),
  control = lmerControl(optCtrl = list(maxfun = 10000)),
  data = multilevel_data_unique)
# added intervention term (period)

intervention_2 <- lmer(
  q_score_scaled ~ 1 + session_scaled*period +
    session_scaled:difficulty +
    domain_id +
    grade +
    session_scaled:domain_id:period +
    session_scaled:grade:period +
    (1 + session_scaled | user_id),
  control = lmerControl(optCtrl = list(maxfun = 10000)),
  data = multilevel_data_unique)
# added interactions between domains & grades with the period
# this is to account for different slopes between grades and domains, when comparing periods
# fit is good

intervention_3 <- lmer(
  q_score_scaled ~ 1 + session_scaled*period +
    session_scaled:difficulty +
    session_scaled:period:ext_deadline_usage +
    domain_id +
    grade +
    session_scaled:domain_id:period +
    session_scaled:grade:period +
    (1 + session_scaled | user_id),
  control = lmerControl(optCtrl = list(maxfun = 10000)),
  data = multilevel_data_unique)
# does not converge;
# adding growth interaction between user-specific usage of extended deadline & period adds these issues
  
intervention_4 <- lmer(
  q_score_scaled ~ 1 + session_scaled*period +
    session_scaled:difficulty +
    period:extended_deadline_group +
    domain_id +
    grade + 
    session_scaled:domain_id:period +
    session_scaled:grade:period +
    (1 + session_scaled | user_id),
  control = lmerControl(optCtrl = list(maxfun = 10000)),
  data = multilevel_data_unique)
# does converge
# categorizing individuals based on extended deadline usage improves model

intervention_5 <- lmer(
  q_score_scaled ~ 1 + session_scaled*period +
    session_scaled:difficulty +
    session_scaled:period:ext_deadline_usage +
    period:extended_deadline_group +
    domain_id +
    grade +
    session_scaled:domain_id:period +
    session_scaled:grade:period +
    (1 + session_scaled | user_id),
  control = lmerControl(optCtrl = list(maxfun = 10000)),
  data = multilevel_data_unique)
# does converge
# for some reason, adding both user-specific usage of extended deadline and group categories
# improves the model; however, BIC indicates over-parametrization

intervention_6 <- lmer(
  q_score_scaled ~ 1 + session_scaled*period +
    session_scaled:difficulty +
    session_scaled:period:ext_deadline_usage +
    period:grade:extended_deadline_group +
    domain_id +
    grade + 
    session_scaled:domain_id:period +
    session_scaled:grade:period +
    (1 + session_scaled | user_id),
  control = lmerControl(optCtrl = list(maxfun = 10000)),
  data = multilevel_data_unique)
# does not converge
# adding interaction between grade & extended deadline usage groups leads to issues
# however, removing user-specific usage of extended deadline (the next model) solves this

intervention_final <- lmer(
  q_score_scaled ~ 1 + session_scaled*period +
    session_scaled:difficulty +
    period:grade:extended_deadline_group +
    domain_id +
    grade +
    session_scaled:domain_id:period +
    session_scaled:grade:period +
    (1 + session_scaled | user_id),
  control = lmerControl(optCtrl = list(maxfun = 10000)),
  data = multilevel_data_unique)
# does converge; BIC improvement
# best model thus far

summary(intervention_5)
summary(intervention_final) 
anova(intervention_5, intervention_final)

# Predictions will be made using intervention_final
# Results show that the slope of growth is larger in the period Oct-Dec
# Improvement is most obvious in lower grades, and in domains 7, 9, 10, 11
# Using domain_rating instead of q_score leads to the same results

# Results from intervention_5 are interesting:
# usage of the extended deadline appears to negatively affect q_score
# however, users who use it rarely seem to benefit most from it, showing higher q_scores
# while those who use it often still have better q_scores than those who never used it

# This could simply result from the fact that players who need and use the extended deadline
# are more likely to have less ability than those who do not
```

```{r}
### Preparation for plots & predictions ###

# Custom theme to share across all plots
custom_theme <- theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    legend.position = "bottom",
    legend.title = element_text(face = "bold"),
    legend.text = element_text(size = 10))

# Create a data-frame for SMOOTH (linear) prediction plots (difficulty = 2)
prediction_smooth <- expand.grid(
  session_scaled = seq(min(multilevel_data_unique$session_scaled),
                       max(multilevel_data_unique$session_scaled), length.out = 20),
  period = unique(multilevel_data_unique$period),
  grade = unique(multilevel_data_unique$grade),
  domain_id = unique(multilevel_data_unique$domain_id),
  difficulty = unique(multilevel_data_unique$difficulty),
  extended_deadline_group = unique(multilevel_data_unique$extended_deadline_group),
  user_id = "dummy_user")
  # necessary to include dummy user id, as it's needed for predict() algorithm
  # however, specific user random effects won't be used in making predictions
  # as allow.new.levels = TRUE allows predictions based on fixed effects only

# Set all obs in Sep-Oct to have extended_deadline_group set to "Never"
prediction_smooth <- prediction_smooth %>%
  mutate(extended_deadline_group = ifelse(period == "Sep-Oct", "Never", as.character(extended_deadline_group)))
prediction_smooth$extended_deadline_group <- factor(prediction_smooth$extended_deadline_group, levels = levels(multilevel_data_unique$extended_deadline_group))

# Add predictions to the grid
prediction_smooth$predicted_q_score_scaled <- predict(intervention_final,
                                                      newdata = prediction_smooth,
                                                      allow.new.levels = TRUE)

# De-scale session & q_score for plots
prediction_smooth <- prediction_smooth %>%
  mutate(
    session = session_scaled * session_sd + session_mean,
    predicted_q_score = predicted_q_score_scaled * q_score_sd + q_score_mean
  ) %>%
  select(-predicted_q_score_scaled, -session_scaled)


# Create data-frame for RAW prediction plots
prediction_raw <- multilevel_data_unique
prediction_raw <- prediction_raw %>%
   mutate(predicted_q_score_scaled = predict(intervention_final, newdata = prediction_raw))

# De-scale session & q_score for plots
prediction_raw <- prediction_raw %>%
  mutate(
    session = session_scaled * session_sd + session_mean,
    predicted_q_score = predicted_q_score_scaled * q_score_sd + q_score_mean
  ) %>%
  select(-predicted_q_score_scaled)
```

```{r}
### Plotting slopes for different periods (across domains, grades, difficulties) ###

## SMOOTH (LINEAR) PLOT ##
# Aggregate over all other unnecessary variables (for this plot)
prediction_summary_smooth <- prediction_smooth %>%
  group_by(session, period) %>%
  summarize(mean_predicted_q_score = mean(predicted_q_score), .groups = "drop")
prediction_summary_smooth$period <- factor(prediction_summary_smooth$period,
                                           levels = c("Sep-Oct", "Oct-Dec"))

### LINEAR - Difference in Ability Growth Between the 2 Periods ###
ggplot(prediction_summary_smooth, aes(x = session, y = mean_predicted_q_score, color = period)) +
  geom_line(aes(group = period), size = 1.2) +
  theme_minimal() +
  labs(
    title = "Linear Model Predictions",
    x = "Session",
    y = "Predicted Q-Score",
    color = "Period"
  ) +
  custom_theme +
  scale_color_manual(values = c("#57b0b5", "#fe6c66"))

## RAW PLOT ##
prediction_summary_raw <- prediction_raw %>%
  group_by(session, period) %>%
  summarize(mean_predicted_q_score = mean(predicted_q_score), .groups = "drop")
prediction_summary_raw$period <- factor(prediction_summary_raw$period,
                                        levels = c("Sep-Oct", "Oct-Dec"))

ggplot(prediction_summary_raw, aes(x = session, y = mean_predicted_q_score, color = period)) +
  geom_line(aes(group = period), size = 1.2) +
  theme_minimal() +
  labs(
    title = "Raw Model Predictions",
    x = "Session",
    y = "Predicted Q-Score",
    color = "Period"
  ) +
  custom_theme +
  scale_color_manual(values = c("#57b0b5", "#fe6c66"))


## Observed (actual) data plot ##
prediction_summary_obs <- prediction_raw %>%
  group_by(session, period) %>%
  summarize(mean_observed_q_score = mean(q_score), .groups = "drop")
prediction_summary_obs$period <- factor(prediction_summary_obs$period,
                                        levels = c("Sep-Oct", "Oct-Dec"))

ggplot(prediction_summary_obs, aes(x = session, y = mean_observed_q_score, color = period)) +
  geom_line(aes(group = period), size = 1.2) +
  theme_minimal() +
  labs(
    title = "Actual Data",
    x = "Session",
    y = "Observed Q-Score",
    color = "Period"
  ) +
  custom_theme +
  scale_color_manual(values = c("#57b0b5", "#fe6c66"))
```


```{r}
### Plots of growth for different domains ###
domains <- c(1, 2, 3, 4, 5, 7, 9, 10, 11, 59)

## LINEAR PLOT ##
# Aggregate over all other unnecessary variables
prediction_summary_smooth <- prediction_smooth %>%
  group_by(period, domain_id, session) %>%
  summarize(mean_predicted_q_score = mean(predicted_q_score), .groups = "drop")
prediction_summary_smooth$period <- factor(prediction_summary_smooth$period,
                                           levels = c("Sep-Oct", "Oct-Dec"))

### LINEAR - Difference in Ability Growth Between the 2 Periods, for all Domains ###
for (i in domains){
  p <- ggplot(prediction_summary_smooth[prediction_summary_smooth$domain_id == i,],
              aes(x = session, y = mean_predicted_q_score, color = period)) +
    geom_line(aes(group = period), size = 1.2) +  # Fit line for each period
    theme_minimal() +
    labs(
      title = paste("Linear Predicted Session and Q-Score by Period, Domain", i),
      x = "Session",
      y = "Predicted Q-Score",
      color = "Period"
    ) +
    scale_color_manual(values = c("#57b0b5", "#fe6c66")) +
    custom_theme
  print(p)
}

## RAW PLOT ##
prediction_summary_raw <- prediction_raw %>%
  group_by(period, domain_id, session) %>%
  summarize(mean_predicted_q_score = mean(predicted_q_score), .groups = "drop")
prediction_summary_raw$period <- factor(prediction_summary_raw$period, levels = c("Sep-Oct", "Oct-Dec"))

for (i in domains){
  p <- ggplot(prediction_summary_raw[prediction_summary_raw$domain_id == i,],
              aes(x = session, y = mean_predicted_q_score, color = period)) +
    geom_line(aes(group = period), size = 1.2) +  # Fit line for each period
    theme_minimal() +
    labs(
      title = paste("Raw Predicted Session and Q-Score by Period, Domain", i),
      x = "Session",
      y = "Predicted Q-Score",
      color = "Period"
    ) +
    scale_color_manual(values = c("#57b0b5", "#fe6c66")) +
    custom_theme
  print(p)
}


## OBSERVED PLOT ##
prediction_summary_obs <- prediction_raw %>%
  group_by(period, domain_id, session) %>%
  summarize(mean_observed_q_score = mean(q_score), .groups = "drop")
prediction_summary_obs$period <- factor(prediction_summary_obs$period,
                                        levels = c("Sep-Oct", "Oct-Dec"))

for (i in domains){
  p <- ggplot(prediction_summary_obs[prediction_summary_obs$domain_id == i,],
              aes(x = session, y = mean_observed_q_score, color = period)) +
    geom_line(aes(group = period), size = 1.2) +  # Fit line for each period
    theme_minimal() +
    labs(
      title = paste("Observed Session and Q-Score by Period, Domain", i),
      x = "Session",
      y = "Observed Q-Score",
      color = "Period"
    ) +
    scale_color_manual(values = c("#57b0b5", "#fe6c66")) +
    custom_theme
  print(p)
}
```

```{r}
### Difference in Ability Growth Between the 2 Periods, for all Grades ###
grades <- c(3, 4, 5, 6, 7, 8)

## LINEAR PLOT ##
# Aggregate over all other unnecessary variables
prediction_summary_smooth <- prediction_smooth %>%
  group_by(period, grade, session) %>%
  summarize(mean_predicted_q_score = mean(predicted_q_score), .groups = "drop")
prediction_summary_smooth$period <- factor(prediction_summary_smooth$period,
                                           levels = c("Sep-Oct", "Oct-Dec"))

for (i in grades){
  p <- ggplot(prediction_summary_smooth[prediction_summary_smooth$grade == i,],
              aes(x = session, y = mean_predicted_q_score, color = period)) +
    geom_line(aes(group = period), size = 1.2) +
    theme_minimal() +
    labs(
      title = paste("Linear Predicted Session and Q-Score by Period, Grade", i),
      x = "Session",
      y = "Predicted Q-Score",
      color = "Period"
    ) +
    scale_color_manual(values = c("#57b0b5", "#fe6c66")) +
    custom_theme
  print(p)
}

## RAW PLOT ##
prediction_summary_raw <- prediction_raw %>%
  group_by(period, grade, session) %>%
  summarize(mean_predicted_q_score = mean(predicted_q_score), .groups = "drop")
prediction_summary_raw$period <- factor(prediction_summary_raw$period,
                                        levels = c("Sep-Oct", "Oct-Dec"))

for (i in grades){
  p <- ggplot(prediction_summary_raw[prediction_summary_raw$grade == i,],
              aes(x = session, y = mean_predicted_q_score, color = period)) +
    geom_line(aes(group = period), size = 1.2) +
    theme_minimal() +
    labs(
      title = paste("Raw Predicted Session and Q-Score by Period, Grade", i),
      x = "Session",
      y = "Predicted Q-Score",
      color = "Period"
    ) +
    scale_color_manual(values = c("#57b0b5", "#fe6c66")) +
    custom_theme
  print(p)
}

## OBSERVED PLOT ##
prediction_summary_obs <- prediction_raw %>%
  group_by(period, grade, session) %>%
  summarize(mean_observed_q_score = mean(q_score), .groups = "drop")
prediction_summary_obs$period <- factor(prediction_summary_obs$period,
                                        levels = c("Sep-Oct", "Oct-Dec"))

for (i in grades){
  p <- ggplot(prediction_summary_obs[prediction_summary_obs$grade == i,],
              aes(x = session, y = mean_observed_q_score, color = period)) +
    geom_line(aes(group = period), size = 1.2) +
    theme_minimal() +
    labs(
      title = paste("Observed Session and Q-Score by Period, Grade", i),
      x = "Session",
      y = "Observed Q-Score",
      color = "Period"
    ) +
    scale_color_manual(values = c("#57b0b5", "#fe6c66")) +
    custom_theme
  print(p)
}
```


```{r}
### Plotting average q_score for different types of users that use the extended deadline ###

## OBSERVED DATA PLOT ##
# results are the same when using predicted q_score values instead of observed ones

# Aggregate over all other unnecessary variables
prediction_summary_raw <- prediction_raw %>%
  filter(period == "Oct-Dec") %>%
  group_by(extended_deadline_group) %>%
  summarize(mean_observed_q_score = mean(q_score), .groups = "drop")

ggplot(prediction_summary_raw, aes(x = extended_deadline_group, y = mean_observed_q_score, color = extended_deadline_group)) +
  geom_point(size = 3, position = position_dodge(width = 0.5)) +  # Mean points
  labs(
    title = "Mean Q-Score by Extended Deadline Usage (Oct-Dec)",
    x = "Extended Deadline Usage",
    y = "Observed Q-score",
    color = "Extended Deadline Usage"
  ) +
  custom_theme +
  theme(legend.position = "none") +
  scale_color_manual(values = c("#008856", "#BE0032", "#0067A5"))
```

```{r}
### Average q_score for different grades & extended deadline usage groupings ###

## OBSERVED DATA PLOT ## 
# results are the same when using predicted q_score values instead of observed ones

# Aggregate over all other unnecessary variables
prediction_summary_raw <- prediction_raw %>%
  filter(period == "Oct-Dec") %>%
  group_by(grade, extended_deadline_group) %>%
  summarize(mean_observed_q_score = mean(q_score),
            mean_predicted_q_score = mean(predicted_q_score), .groups = "drop")

prediction_summary_raw %>%
  ggplot(aes(x = grade, y = mean_observed_q_score, color = extended_deadline_group)) +
  geom_point(size = 1.5) +
  labs(
    title = "Q-Scores by Extended Deadline Usage & Grade (Oct-Dec)",
    x = "Grade",
    y = "Observed Q-score",
    color = "Extended Deadline Usage"
  ) +
  custom_theme +
  scale_color_manual(values = c("green", "red", "blue"))

```



### MOTIVATION

```{r}
# Total number of unique users
num_users <- n_distinct(ed_logs$user_id)
# 23305

# Finding users that alternate between showing coins and not
swappers <- ed_logs %>%
  select(user_id, show_coins) %>%
  distinct(user_id, show_coins) %>%       # Get unique choices
  count(user_id) %>%                    
  filter(n == 2) %>%                    
  pull(user_id)
# 11118 users have swapped at least once
# Proportion
length(swappers) / num_users # .477065

# Finding users that have never swapped between showing coins or not
not_swappers <- ed_logs %>%
  select(user_id, show_coins) %>%
  distinct(user_id, show_coins) %>%       # Get unique choices
  count(user_id) %>%                    
  filter(n == 1) %>%                    
  pull(user_id)
# 12187 users have never swapped
# Proportion
length(not_swappers) / num_users # .522935

# Users that don't show coins
no_shows <- ed_logs %>%
  distinct(user_id, show_coins) %>%
  filter(user_id %in% not_swappers & show_coins == 0) %>%
  pull(user_id)
# 132 users never showed coins
# Proportion
length(no_shows) / num_users # .005664021

```


```{r}
# Investigating swapping behavior, especially for those swapping to show coins after change

# Getting data needed for sankey plot
sankey_data <- ed_logs %>%
  select(user_id, show_coins, time_weeks) %>%
  filter(user_id %in% swappers) %>%
  mutate(interval = cut(time_weeks, breaks = seq(0, max(time_weeks), by = 2), labels = FALSE))


# Group by individual and interval, then summarize
sankey_tibble <- sankey_data %>%
  group_by(user_id, interval) %>%
  summarize(mode_show_coins = names(which.max(table(show_coins)))) %>%
  ungroup()

# Make the plot
sankey_tibble %>%
ggplot(aes(x = interval, stratum = mode_show_coins, alluvium = user_id, fill = mode_show_coins, label = mode_show_coins)) +
  theme_minimal() +
  #scale_fill_manual(values = color_scheme2) +
  geom_flow(color = "darkgray") +
  geom_stratum() +
  theme(legend.position = "top") +
  labs(x = "2-Week Intervals", y = "Users", title = "Mode show_coins across 2-Week Intervals", legend = "Mode show_coins")
```

Zooming into this year and changing to weekly.

```{r}
# Getting data needed for sankey plot
sankey_data <- ed_logs %>%
  select(user_id, show_coins, time_weeks, date) %>%
  filter(user_id %in% swappers,
         time_weeks > 52) %>%
  mutate(interval = cut(time_weeks, breaks = seq(0, max(time_weeks), by = 2), labels = FALSE)) %>%
  group_by(interval) %>%
  mutate(start_date = as.character(min(as.Date(date)))) %>%  # Assign the earliest date in the interval
  ungroup()


# Group by individual and interval, then summarize
sankey_tibble <- sankey_data %>%
  group_by(user_id, interval, start_date) %>%
  summarize(mode_show_coins = names(which.max(table(show_coins)))) %>%
  ungroup() %>%
  mutate(mode_show_coins = if_else(mode_show_coins == 0, "No Show", "Show"))

# Make the plot
coins_sankey <- sankey_tibble %>%
ggplot(aes(x = start_date, stratum = mode_show_coins, alluvium = user_id, fill = mode_show_coins, label = mode_show_coins)) +
  theme_minimal() +
  geom_flow(color = "darkgray") +
  geom_stratum() +
  custom_theme +
  labs(x = "Interval Start Date", y = "Users", title = "Coin Showing Choice Mode Change in 2-week Intervals", fill = "Mode show_coins")

coins_sankey
ggsave("Jan Group/Plots/Show_coins_Sankey.jpeg")

```


Between section 30 and 31 is when the change is made. Which happens to also be paired by a major exodus of students from not showing to then showing, meaning that at least to some extent communication of the feature has occurred outside of personal experience.

```{r}
# Looking deeper. Investigating if students who've never shown coins between sep 1st 2024 and oct 25th 2024 are part of that exodus
stuff <- ed_logs %>%
  select(user_id, show_coins, time_weeks, date) %>%
  filter(user_id %in% swappers, 
         time_weeks %in% 52:64) %>%
  arrange(user_id, time_weeks)

# Users who never showed coins in section 30 where change occurs
unknowners <- stuff %>%
  filter(time_weeks %in% 52:60) %>%    # Keep only rows within the specified weeks
  group_by(user_id) %>%                   # Group by user
  filter(all(show_coins == 0)) %>%        # Keep only users with all 0s across the weeks
  distinct(user_id) %>%
  pull(user_id)

# Users who used coins directly after the change
coiners <- stuff %>%
  group_by(user_id, time_weeks) %>%
  filter(time_weeks %in% 61:62 & any(show_coins == 1)) %>%
  distinct(user_id) %>% 
  pull(user_id)

# Users who went from never showing to showing after the change
enlightened <- stuff %>%
  filter(user_id %in% unknowners & user_id %in% coiners) %>%
  distinct(user_id) %>%
  pull(user_id)

# Proportion of users who went from not showing coins at all before the change, to showing after change
length(enlightened) / length(unknowners) # 0.6403509

```

With over about 64% of users who weren't showing coins changing to showing coins after the change, and showing coins is the only way to see if you're going into extended time, this provides some evidence that communication between students about the extended deadline is likely. However! this could also just be due to students curious about if what changes have been made to the coin animation.

If they now show coins more often than not this could be a sign that it is not initial curiosity, since the coin animation hasn't really changed, but rather is being used as a tool for checking the time, which is evidence of it being knowledge they gained from other students.

```{r}
# Do they show coins more than 1 session
# Count of show_coin setting for never showers who became showers after the change 
show_count <- stuff %>%
  filter(user_id %in% enlightened, time_weeks > 60) %>%
  group_by(user_id, show_coins) %>%
  summarize(count = n(), .groups = "drop") 

# Line chart ordered by proportion of showing coins
coins_plot <- show_count %>%
  group_by(user_id) %>%
  mutate(total = sum(count),                         
    prop = sum(count[show_coins == 1]) / total 
  ) %>%
  ungroup() %>%
  mutate(user_id = reorder(user_id, -total, mean)) %>%
  mutate(user_id = reorder(user_id, -prop, mean)) %>% # Reorder by proportion
ggplot(aes(x = user_id, y = count, color = factor(show_coins), group = show_coins)) +
  geom_line() +
  scale_color_manual(values = c("1" = "#00bfc4", "0" = "#f8766d"),
                     labels = c("Not Showing", "Showing"),
                     name = "Coins") +
  labs(title = "User Coin Showing Behavior", subtitle = "Ordered by Proportion of Coins Showing & Total Played", x = "Users", y = "Count") +
  custom_theme +
  theme(axis.text.x = element_blank())

coins_plot
ggsave("Jan Group/Plots/Coin Showing.jpeg")


calc <- show_count %>%
  group_by(user_id) %>%
  mutate(total = sum(count),                         
    prop = sum(count[show_coins == 1]) / total 
  ) %>%
  ungroup() 
paste0("Of users who switched from never showing to showing ", round(sum(calc$prop >= .5) / nrow(calc) * 100, 2), "% of them stuck with showing coins most of the time.")
```

We see that the majority of those who switched coins on, most of the time kept coins on which is a substantial change from their previous behavior.


```{r}
# Change in difficulty selection data
# Getting data needed for sankey plot
sankey_data <- ed_logs %>%
  select(user_id, difficulty, time_weeks, date) %>%
  filter(time_weeks > 52) %>%
  mutate(interval = cut(time_weeks, breaks = seq(0, max(time_weeks), by = 2), labels = FALSE)) %>%
  group_by(interval) %>%
  mutate(start_date = min(as.Date(date))) %>%  # Assign the earliest date in the interval
  ungroup()

sankey_data <- sankey_data %>%
  mutate(difficulty = factor(
    difficulty,
    levels = c(0, 1, 2),
    labels = c("Easy", "Medium", "Hard")))

# Group by individual and interval, then summarize
sankey_tibble <- sankey_data %>%
  group_by(user_id, interval, start_date) %>%
  summarize(Mode_difficulty = names(which.max(table(difficulty)))) %>%
  ungroup() %>%
  mutate(start_date = as.character(start_date))
  

color_scheme2 <- c(
  "Easy" = "#008856",
  "Medium" = "#0067A5",
  "Hard" = "#BE0032"
)

```


```{r}
# Change in difficulty selection plot
# Make the sankey plot
dif_sankey <- sankey_tibble %>%
ggplot(aes(x = start_date, stratum = Mode_difficulty, alluvium = user_id, fill = Mode_difficulty, label = Mode_difficulty)) +
  scale_fill_manual(values = color_scheme2) +
  geom_flow(color = "darkgray") +
  geom_stratum() +
  custom_theme +
  labs(x = "Interval Start Date", y = "Users", title = "Difficulty Chosen Most Often across 2-Week Intervals", legend = "Mode Difficulty")

dif_sankey
ggsave("Jan Group/Plots/Mode Difficulty Sankey.jpeg")

```


A large initial migration to medium difficulty on the day of the change. A surprising amount from hard, and an understandable amount from easy. Curiously, after the initial migration there is a consistent move back to hard difficulty for some. The amount of students in easy is noticeably lower after the change. 
Do these students who have left easy use the extended deadline?

```{r}
# Extended deadline/difficulty data
ed_diff_data <- ed_logs %>%
  select(user_id, difficulty, time_weeks, late_response, answer) %>%
  mutate(interval = cut(time_weeks, breaks = seq(0, max(time_weeks), by = 2), labels = FALSE),
         difficulty = factor(difficulty,
                             levels = c(0, 1, 2),
                             labels = c("Easy", "Medium", "Hard"))) %>%
  filter(interval > 29)

ed_diff_tibble <- ed_diff_data %>%
  group_by(user_id, interval) %>%
  summarize(mode_difficulty = names(which.max(table(difficulty))),
            extended_deadline_total = sum(late_response == 1 & answer != "…"),
            non_response_total = sum(answer == "…")) %>%
  ungroup()

```


```{r}
# Getting data for graphing response type and switch type
# Interaction of leaving easy and extended deadline
braves_all <- ed_diff_tibble %>%
  group_by(user_id) %>%
  mutate(first_cat = first(mode_difficulty), 
         switched = mode_difficulty != first_cat & interval > 1)

# Grouping and labeling based on switching and starting choices
suppressWarnings(switch_tracking_all <- braves_all %>% # Gives a false warning about inf
  group_by(user_id) %>%
  mutate(first_switch_week = if_else(switched, interval, NA_integer_), # Week of switch
    first_switch_week = case_when(any(switched) ~ min(first_switch_week, na.rm = TRUE),
                                  TRUE ~ NA_integer_),# Get the earliest switch
    stay_switched = if_else(                           # Check if they stay switched
      interval >= first_switch_week & switched, 
      mode_difficulty, 
      NA_character_
    )
  )) 
# Groups labeled and response types counted
stayers_all <- switch_tracking_all %>%
  summarise(
    switch_category = case_when(
      all(na.omit(switched) == first(na.omit(switched))) ~ "Never Switched",
      first(na.omit(switched)) == last(na.omit(switched)) ~ "Did Not Stay Switched",
      TRUE ~ "Stayed Switched"
    ),
    first_cat = first(mode_difficulty)
  ) %>%
  ungroup()

stayers_all <- switch_tracking_all %>%
  summarise(
    stayed_switched = case_when(
      # Never switched: all intervals are NA or the same as the first non-NA value
      all(na.omit(switched) == first(na.omit(switched))) & first(first_cat) == "Easy" ~ "Never Switched - Easy",
      all(na.omit(switched) == first(na.omit(switched))) & first(first_cat) == "Medium" ~ "Never Switched - Medium",
      all(na.omit(switched) == first(na.omit(switched))) & first(first_cat) == "Hard" ~ "Never Switched - Hard",
      # Did Not Stay Switched: First and last are the same but switched at some point
      first(na.omit(switched)) == last(na.omit(switched)) & first(first_cat) == "Easy" ~ "Didn't Stay Switched - Easy",
      first(na.omit(switched)) == last(na.omit(switched)) & first(first_cat) == "Medium" ~ "Didn't Stay Switched - Medium",
      first(na.omit(switched)) == last(na.omit(switched)) & first(first_cat) == "Hard" ~ "Didn't Stay Switched - Hard",
      # Stayed Switched: First and last are different
      first(first_cat) == "Easy" ~ "Stayed Switched - Easy",
      first(first_cat) == "Medium" ~ "Stayed Switched - Medium",
      first(first_cat) == "Hard" ~ "Stayed Switched - Hard",
      # Default case (in case of unexpected values)
      TRUE ~ "Unknown"
    )
  ) %>%
  ungroup()

# Getting total members
stayers_all %>%
  summarise(easy_never = sum(stayed_switched == "Never Switched - Easy"),
            medium_never = sum(stayed_switched == "Never Switched - Medium"),
            hard_never = sum(stayed_switched == "Never Switched - Hard"),
            easy_didnt = sum(stayed_switched == "Didn't Stay Switched - Easy"),
            medium_didnt = sum(stayed_switched == "Didn't Stay Switched - Medium"),
            hard_didnt = sum(stayed_switched == "Didn't Stay Switched - Hard"),
            easy_stayed = sum(stayed_switched == "Stayed Switched - Easy"),
            medium_stayed = sum(stayed_switched == "Stayed Switched - Medium"),
            hard_stayed = sum(stayed_switched == "Stayed Switched - Hard"))

# Joining switch labels and ed_logs relevant stuff
fgb_data <- ed_logs %>%
  select(user_id, difficulty, time_weeks, late_response, answer, date) %>%
  mutate(interval = cut(time_weeks, breaks = seq(0, max(time_weeks), by = 2), labels = FALSE),
         difficulty = factor(difficulty,
                             levels = c(0, 1, 2),
                             labels = c("Easy", "Medium", "Hard"))) %>%
  group_by(user_id, interval) %>%
  summarize(mode_difficulty = names(which.max(table(difficulty))),
            extended_deadline_total = sum(late_response == 1 & answer != "…"),
            non_response_before = sum(answer == "…" & date < change_date, na.rm = TRUE),
            non_response_after = sum(answer == "…" & date >= change_date, na.rm = TRUE),
            total_before = sum(date < change_date, na.rm = TRUE),
            total_after = sum(date >= change_date, na.rm = TRUE),
            .groups = "drop")
  
collapsed_fgb <- fgb_data %>%
  group_by(user_id) %>%
  summarize(
    extended_deadline = sum(extended_deadline_total, na.rm = TRUE),
    no_answer_before = sum(non_response_before, na.rm = TRUE),
    no_answer_after = sum(non_response_after, na.rm = TRUE)
  ) %>%
  left_join(stayers_all, by = "user_id") %>%
  filter(!is.na(stayed_switched))


collapsed_long <- collapsed_fgb %>%
  pivot_longer(cols = c(extended_deadline, no_answer_before, no_answer_after),
               names_to = "response_type",
               values_to = "value"
  ) %>%
  mutate(stayed_switched = factor(stayed_switched, 
                                  levels = c("Didn't Stay Switched - Easy", "Didn't Stay Switched - Medium", "Didn't Stay Switched - Hard", "Stayed Switched - Easy", "Stayed Switched - Medium", "Stayed Switched - Hard", "Never Switched - Easy", "Never Switched - Medium", "Never Switched - Hard")),
         response_type = factor(response_type,
                                levels = c("no_answer_before", "no_answer_after", "extended_deadline"),
                                labels = c("No Answer Before", "No Answer After", "Late Response"))
  )
```


```{r}
# All combined
# Setting Color Scheme
response_color <- c(
  "Late Response" = "#E69F00",
  "No Answer Before" = "#00bfc4",
  "No Answer After" = "#f8766d"
)

# Faceted bar graph
full_plot <- ggplot(collapsed_long, aes(x = response_type, y = value, fill = response_type)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = response_color) +
  labs(
    title = "Response Type Totals",
    x = "Response Type",
    y = "Total Responses",
    fill = "Response Type"
  ) +
  custom_theme +
  theme(
    strip.text = element_text(size = 12),
    legend.position = "bottom",
    axis.title.x = element_blank(),
    axis.text.x = element_blank()
  ) 

full_plot
ggsave("Jan Group/Plots/Response Totals.jpeg")
```



```{r}
# Faceted bar graph
fb_plot <- ggplot(collapsed_long, aes(x = response_type, y = value, fill = response_type)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = response_color) +
  labs(
    title = "Response Totals by Difficulty Switching Category",
    x = "Response Type",
    y = "Total Responses",
    fill = "Response Type"
  ) +
  custom_theme +
  facet_wrap(~ stayed_switched) +
  theme(
    strip.text = element_text(size = 10),
    legend.position = "bottom",
    axis.title.x = element_blank(),
    axis.text.x = element_blank()
  ) 

fb_plot
ggsave("Jan Group/Plots/Response totals by Difficulty.jpeg")

```

how many rage quits after non-answer before vs how many rq after late response and/or non-answer after. soft quits after late response, vs non_response. Use Threshold modelling (psych) for measuring build up and response w/ and w/out for quitting.

```{r}
# Of note, domain 5 is the only to not have 10/session but 15
# Data for motivation analysis: soft-quit, hard-quit, sessions per instance
motivation_data <- ed_logs %>%
  select(user_id, answer, date, new_user_domain_session_count, correct_answered, grade, domain_id, deadline, late_response, session, response_in_seconds) %>%
  rename(session_number = new_user_domain_session_count) %>%
  # Getting users who have before and after data and just this school year
  mutate(change = if_else(date < change_date, "Before", "After")) %>%
  filter(date > as.Date("2024-09-02") & any(change == "After")) %>%
  # For calculating hard quitting
  arrange(user_id, date) %>%
  mutate(
    time_diff = as.numeric(difftime(date, lag(date, default = first(date)), units = "mins")),
    play_sesh = cumsum(ifelse(is.na(time_diff) | time_diff > 30, 1, 0))
  ) %>%
  # Make hard quitting tracker
  group_by(user_id, play_sesh) %>%
  mutate(
    hard_quit = if_else(lead(play_sesh, default = first(play_sesh)) != play_sesh | is.na(lead(play_sesh)), TRUE, FALSE)
  ) %>%
  ungroup() %>%
  select(-time_diff)

# Keeping track of soft-quitting and afk in session
softies <- motivation_data %>%
  select(user_id, domain_id, session_number, play_sesh, session) %>%
  mutate(full = if_else(domain_id == 5, 15, 10)) %>%
  group_by(user_id, domain_id, session_number, play_sesh, session, full) %>%
  summarise(count = n(),
            soft_quit = case_when(all(count != full & session == "domain") ~ TRUE,
                           all(count == full & session == "domain") ~ FALSE,
                           all(count %% full != 0 & session == "learning_goal") ~ TRUE,
                           all(count %% full == 0 & session == "learning_goal") ~ FALSE,
                           TRUE ~ NA),
            .groups = "drop") %>%
  select(-count, -full)


# Merging soft-quit into motivation data
motivation_data <- motivation_data %>%
  left_join(softies) %>%
  mutate(response_timing = case_when(late_response == 1 & answer != "…" ~ "extended",
                                     answer == "…" & date < change_date ~ "non_response_before",
                                     answer == "…" & date >= change_date ~ "non_response_after",
                                     TRUE ~ "on_time"))

# Calculating if session had likely afk
afking <- motivation_data %>%
  group_by(user_id, domain_id, session_number, play_sesh, session) %>%
  summarise(afk = any(rle(answer == "…")$values & rle(answer == "…")$lengths >= 3))
  
# Merging back into motivation_data
motivation_data <- motivation_data %>%
  left_join(afking) %>%
  mutate(change = factor(change, levels = c("Before", "After")))
```

```{r}
# Making the visualizations
# Color Pallette
before_after_color <- c("Before" = "#00bfc4",
                  "After" = "#f8766d")

# Plotting percent of soft quitting and afking before and after change
afk_sq_plot <- motivation_data %>%
  group_by(change) %>%
  summarise(
    soft_quitting_count = sum(soft_quit),      
    afking_count = sum(afk),                  
    soft_quitting = soft_quitting_count / n() * 100,  
    afking = afking_count / n() * 100,       
    .groups = "drop"
  ) %>%
  pivot_longer(
    cols = c(soft_quitting, afking),
    names_to = "quit_type",
    values_to = "value"
  ) %>%
  pivot_longer(
    cols = c(soft_quitting_count, afking_count),
    names_to = "quit_type_count",
    values_to = "count",
    names_transform = list(quit_type_count = ~ gsub("_count", "", .x)) # Clean names
  ) %>%
  filter(quit_type == quit_type_count) %>% # Match percentage and counts
  ggplot(aes(x = quit_type, y = value, fill = change)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(
    aes(label = count, group = change),
    position = position_dodge(width = 0.9),
    vjust = 1.5
  ) +
  scale_fill_manual(values = before_after_color) +
  scale_y_continuous(labels = label_percent(scale = 1)) + # Format y-axis as percentages
  labs(
    title = "Problem Quitting Percentages Before and After UI Change",
    x = "Quitting Type",
    y = "Percent of Responses",
    fill = "Timing"
  ) +
  custom_theme

afk_sq_plot
ggsave("Jan Group/Plots/Soft Quitting and AFK.jpeg")

```


How much of hard quitting had a soft quit before it vs a complete session, before and after the change?

```{r}
# Color Pallet
soft_complete_color <- c("completed_session" = "#00bfc4",
                  "soft_quitting" = "#f8766d")

# Plotting percent of hard quits after soft-quit vs completed session
pie_data <- motivation_data %>%
  filter(hard_quit == TRUE) %>%
  group_by(change) %>%
  summarise(
    soft_quitting_count = sum(soft_quit),      
    completed_session_count = sum(!soft_quit),          
    soft_quitting = soft_quitting_count / n() * 100,  
    completed_session = completed_session_count / n() * 100,  
    .groups = "drop"
  ) %>%
  pivot_longer(
    cols = c(soft_quitting, completed_session),
    names_to = "quit_type",
    values_to = "value"
  ) %>%
  pivot_longer(
    cols = c(soft_quitting_count, completed_session_count),
    names_to = "quit_type_count",
    values_to = "count",
    names_transform = list(quit_type_count = ~ gsub("_count", "", .x))  # Clean names
  ) %>%
  filter(quit_type == quit_type_count) # Match percentage and counts

pie <- pie_data %>%  
  ggplot(aes(x = "", y = value, fill = quit_type)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +  # Convert to pie chart
  facet_wrap(~ change) +  # Facet by 'before' or 'after'
  geom_text(
    aes(label = paste0(quit_type, "\n", round(value, 1), "%\n", count)), 
    position = position_stack(vjust = 0.5)
  ) +
  scale_fill_manual(values = soft_complete_color) +
  labs(
    title = "Application Closed After Quitting a Session Early",
    x = NULL, y = NULL,
    fill = "Quit Type"
  ) +
  theme_void() +  # Use theme_void to remove axis and grid lines for pie charts
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    strip.text = element_text(size = 12),
    legend.position = "none"
  )

pie
ggsave("Jan Group/Plots/Hard Quit: Soft vs Complete.jpeg")

```


Cox Proportional Hazards Model to check if extended_deadline use has an increased probability of continuing to play.


```{r}
# Function to plot the different survival curves
surv_plotter <- function(surv_fit_grouped, groups = c("No Extension Used", "Extension Used"), title_specification, xlimit){

# Color Pallet
custom_color <- c("#f8766d", "#00bfc4")

# Convert summary to dataframe
surv_df_grouped <- data.frame(
  time = surv_fit_grouped$time,
  surv_0 = surv_fit_grouped$surv[, 1],  
  surv_1 = surv_fit_grouped$surv[, 2],  
  lower_0 = surv_fit_grouped$lower[, 1],  
  lower_1 = surv_fit_grouped$lower[, 2],  
  upper_0 = surv_fit_grouped$upper[, 1],  
  upper_1 = surv_fit_grouped$upper[, 2]   
)

# Pivot to long format
plot <- surv_df_grouped %>%
  pivot_longer(cols = -time, 
               names_to = c(".value", "Group"),
               names_sep = "_") %>%
  mutate(Group = factor(Group, levels = c("0", "1"), labels = groups)) %>%


# Plot grouped Cox-Adjusted Kaplan-Meier curves
ggplot(aes(x = time, y = surv, color = Group)) +
  scale_color_manual(values = custom_color) +
  geom_step() +
  xlim(0, xlimit) +
  geom_ribbon(aes(ymin = lower, ymax = upper, fill = Group), alpha = 0.2) +
  labs(x = "Time (seconds)",
       y = "Survival Probability", 
       title = "Cox-Adjusted Survival Curves",
       subtitle = title_specification) +
  custom_theme 

return(plot)
}
```


```{r}
# Creating data for soft_quitting survival checking
cox_data_soft <- motivation_data %>%
  # Because time format was refusing to work
  mutate(seconds_since_midnight = hour(date) * 3600 + minute(date) * 60 + second(date)) %>%
  group_by(user_id, play_sesh, session_number, domain_id, session) %>%
  summarise(duration = ifelse(n() > 1, # Some times only 1 item played
                       as.integer(max(seconds_since_midnight) - min(seconds_since_midnight)), 
                       as.integer(response_in_seconds)),
            extended_deadline_used = any(response_timing == "extended"),
            soft_quit = any(soft_quit),
            hard_quit = any(hard_quit),
            change = first(change),
            .groups = "drop"
  )

```

Duration could use further investigation, considering there are some sessions with extreme durations, could be interesting for checking for afks. A decent amount have soft_quit and/or hard_quit true (eyeballing it seems like if soft_quit is true then hard_quit usually is) but plenty don't. Interesting.

```{r}
# Creating data for hard_quitting survival checking
cox_data_hard <- motivation_data %>%
  mutate(seconds_since_midnight = hour(date) * 3600 + minute(date) * 60 + second(date)) %>%
  group_by(user_id, play_sesh) %>%
  summarise(
    duration = ifelse(n() > 1, 
                      as.integer(max(seconds_since_midnight) - min(seconds_since_midnight)), 
                       as.integer(response_in_seconds)),
    extended_deadline_used = any(response_timing == "extended"),
    soft_quit = any(soft_quit),
    hard_quit = any(hard_quit),
    change = first(change),
    .groups = "drop"
  )
```

Duration is interesting yet again, but for a different reason. It turns out that there seems to be a surprising amount of application runs that only consist of performing a single item and then quitting completely. Interesting for future investigation possibly.




```{r, warning=FALSE}
# Cox model to determine survival probability on session length
cox_model_soft <- coxph(Surv(duration, soft_quit) ~ extended_deadline_used, data = cox_data_soft)

# Model fitting for plotting
cox_fit_soft <- survfit(cox_model_soft, newdata = data.frame(extended_deadline_used = c(0, 1)))

# Plot it
se_plot <- surv_plotter(cox_fit_soft, title_specification = ("Extended Duration and Mid-Session Quitting"), xlimit = 5000)

se_plot
ggsave("Jan Group/Plots/Soft Quitting Cox-Curve: Extended Duration.jpeg")

```

What about if we only include since the UI change?

```{r, warning=FALSE}
# Filtered data
cox_data_soft_after <- cox_data_soft %>%
  filter(change == "After")
# Cox model to determine survival probability on session length
cox_model_soft_after <- coxph(Surv(duration, soft_quit) ~ extended_deadline_used, data = cox_data_soft_after)

# Model fitting for plotting
cox_fit_soft_after <- survfit(cox_model_soft_after, newdata = data.frame(extended_deadline_used = c(0, 1)))

# Plot it
se_after_plot <- surv_plotter(cox_fit_soft_after, title_specification = ("Extended Duration and Mid-Session Quitting: After"), xlimit = 5000)

se_after_plot
ggsave("Jan Group/Plots/Soft Quitting Cox-Curve: Extended Duration only After.jpeg")

```

It appears that the main difference is just the increased confidence intervals due to having less data. This is very promising evidence that the extended deadline is helping students stick with their sessions.


```{r, warning=FALSE}
# Cox model to determine survival probability on session length
cox_model_hard <- coxph(Surv(duration, hard_quit) ~ extended_deadline_used, data = cox_data_hard)

# Model fitting for plotting
cox_fit_hard <- survfit(cox_model_hard, newdata = data.frame(extended_deadline_used = c(0, 1)))

# Plot it
he_plot <- surv_plotter(cox_fit_hard, title_specification = ("Extended Duration and Application Quitting"), xlimit = 5000)

he_plot
ggsave("Jan Group/Plots/Hard Quitting Cox-Curve: Extended Duration.jpeg")

```

```{r, warning=FALSE}
# Filtered data
cox_data_hard_after <- cox_data_hard %>%
  filter(change == "After")
# Cox model to determine survival probability on session length
cox_model_hard_after <- coxph(Surv(duration, hard_quit) ~ extended_deadline_used, data = cox_data_hard_after)

# Model fitting for plotting
cox_fit_hard_after <- survfit(cox_model_hard_after, newdata = data.frame(extended_deadline_used = c(0, 1)))

# Plot it
he_after_plot <- surv_plotter(cox_fit_hard_after, title_specification = ("Extended Duration and Application Quitting: After"), xlimit = 5000)

he_after_plot
ggsave("Jan Group/Plots/Hard Quitting Cox-Curve: Extended Duration only After.jpeg")

```

It is only slightly, however, the gap between using the extended deadline and not has actually increased, with extended increasing in survival chance and non-extended use decreasing in survival chance. Again, more evidence that it is a helpful intervention for motivating students to keep going. 


```{r}
# Testing with runs of at least 1 session played
# Creating data for hard_quitting survival checking
cox_data_hard_complete <- motivation_data %>%
  mutate(seconds_since_midnight = hour(date) * 3600 + minute(date) * 60 + second(date)) %>%
  group_by(user_id, play_sesh) %>%
  summarise(duration = ifelse(n() > 1, 
                              as.integer(max(seconds_since_midnight) - min(seconds_since_midnight)), 
                              response_in_seconds),
            extended_deadline_used = any(response_timing == "extended"),
            complete_session = any(soft_quit == FALSE),
            soft_quit = any(soft_quit),
            hard_quit = any(hard_quit),
            .groups = "drop"
  ) %>%
  filter(complete_session == TRUE)
```

Still quite a lot of application runs that are very short even when running at least 1 complete session. 

```{r, warning=FALSE}
# Cox model to determine survival probability on session length
cox_model_hard_complete <- coxph(Surv(duration, hard_quit) ~ extended_deadline_used, data = cox_data_hard_complete)

# Model fitting for plotting
cox_fit_hard_complete <- survfit(cox_model_hard_complete, newdata = data.frame(extended_deadline_used = c(0, 1)))

# Plot it
surv_plotter(cox_fit_hard_complete, groups = c("no extended", "extended"), title_specification = ("Extended Duration and Application Quitting: At Least 1"), xlimit = 5000)

```

Also doesn't seem to change the curve very much, only increasing the survival chance very slightly.



```{r}
oefenwebDatabase::close_connection(con)
```

