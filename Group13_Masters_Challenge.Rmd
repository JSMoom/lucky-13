---
title: "Untitled"
author: "Ender Alexandru, Laura Fetz, Jessee Moomey"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
# Loading packages
library(cowplot)
library(scales)
library(plotly)
library(gridExtra)
library(tidyverse)
library(devtools)
library(oefenwebDatabase)
library(oefenwebTools)
library(lme4)
library(lmerTest)
library(lubridate)
library(DBI)
library(ggalluvial)
library(survival)
# Establishing connection with oefenweb
con <- oefenwebDatabase::connect()
```

Grab the data from original database

```{r}
# Create necessary objects
ed_logs <- list()
domains <- c(1:5, 7, 9, 10, 11, 59)
change_date <- as.Date("2024-10-25")
start_date <- as.Date("2023-09-01")
custom_theme <- theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    legend.position = "bottom",
    legend.title = element_text(face = "bold"),
    legend.text = element_text(size = 10),
    plot.subtitle = element_text(hjust = 0.5, face = "bold", size = 10)
  )

# Loop through each E_D table
for (i in 1:10) {
  # Write SQL query to get data, and convert to seconds
  query <- paste0("SELECT *
                   FROM extended_deadline_logs_", domains[i])
  # Get the data and store it in the list
  ed_logs[[i]] <- suppressWarnings(DBI::dbGetQuery(con, query))
}

# Turn the list into a single df
ed_logs <- bind_rows(ed_logs)

# Getting deadlines for items in 59
query <- paste0("SELECT id AS item_id,
                 maximum_response_in_seconds AS deadline
                 FROM extended_deadline_items
                 WHERE domain_id = 59")
  # Get the data and store it in the list
deadlines_59 <- suppressWarnings(DBI::dbGetQuery(con, query))

# Convert created to date and into POSIXct format
ed_logs <- ed_logs %>%
  rename(date = created) 
ed_logs$date <-
  as.POSIXct(ed_logs$date, format = "%Y-%m-%d %H:%M:%S")
```


```{r}
# Getting item deadlines for domain 59
items_5 <- deadlines_59 %>%
  filter(deadline == 5) %>%
  pull(item_id)

items_10 <- deadlines_59 %>%
  filter(deadline == 10) %>%
  pull(item_id)

items_15 <- deadlines_59 %>%
  filter(deadline == 15) %>%
  pull(item_id)

items_20 <- deadlines_59 %>%
  filter(deadline == 20) %>%
  pull(item_id)

# Categorical columns
cats <- colnames(ed_logs[,c(8:11, 14:15)])

# Adjustments to data
ed_logs = ed_logs %>%
  rename(response_in_seconds = response_in_milliseconds) %>%
  mutate(deadline = case_when(
    domain_id %in% c(1:4, 7, 10) ~ 20,
    domain_id == 9 ~ 30,
    domain_id == 11 ~ 60,
    domain_id == 5 ~ 8,
    domain_id == 59 & item_id %in% items_5 ~ 5,
    domain_id == 59 & item_id %in% items_10 ~ 10,
    domain_id == 59 & item_id %in% items_15 ~ 15,
    domain_id == 59 & item_id %in% items_20 ~ 20),
    response_in_seconds = response_in_seconds / 1000,
    across(all_of(cats), as.factor)
  ) 
# Adding time_weeks column and organizing by user_id then date
ed_logs <- ed_logs %>%
  group_by(user_id) %>%
  arrange(user_id, date) %>%
  mutate(time_weeks = ceiling(as.numeric(
    difftime(date, start_date, units = "weeks")
  ))) %>%
  mutate(time_weeks = ifelse(time_weeks < 1, 1, time_weeks),
         late_response = ifelse(response_in_seconds > deadline, 1, 0)) %>%  # Ensure any negative or 0 values are set to 1
  ungroup() 

```


```{r}
# Total number of unique users
num_users <- n_distinct(ed_logs$user_id)
# 23305

# Finding users that alternate between showing coins and not
swappers <- ed_logs %>%
  select(user_id, show_coins) %>%
  distinct(user_id, show_coins) %>%       # Get unique choices
  count(user_id) %>%                    
  filter(n == 2) %>%                    
  pull(user_id)
# 11118 users have swapped at least once
# Proportion
length(swappers) / num_users # .477065

# Finding users that have never swapped between showing coins or not
not_swappers <- ed_logs %>%
  select(user_id, show_coins) %>%
  distinct(user_id, show_coins) %>%       # Get unique choices
  count(user_id) %>%                    
  filter(n == 1) %>%                    
  pull(user_id)
# 12187 users have never swapped
# Proportion
length(not_swappers) / num_users # .522935

# Users that don't show coins
no_shows <- ed_logs %>%
  distinct(user_id, show_coins) %>%
  filter(user_id %in% not_swappers & show_coins == 0) %>%
  pull(user_id)
# 132 users never showed coins
# Proportion
length(no_shows) / num_users # .005664021

```


```{r}
# Investigating swapping behavior, especially for those swapping to show coins after change

# Getting data needed for sankey plot
sankey_data <- ed_logs %>%
  select(user_id, show_coins, time_weeks) %>%
  filter(user_id %in% swappers) %>%
  mutate(interval = cut(time_weeks, breaks = seq(0, max(time_weeks), by = 2), labels = FALSE))


# Group by individual and interval, then summarize
sankey_tibble <- sankey_data %>%
  group_by(user_id, interval) %>%
  summarize(mode_show_coins = names(which.max(table(show_coins)))) %>%
  ungroup()

# Make the plot
sankey_tibble %>%
ggplot(aes(x = interval, stratum = mode_show_coins, alluvium = user_id, fill = mode_show_coins, label = mode_show_coins)) +
  theme_minimal() +
  #scale_fill_manual(values = color_scheme2) +
  geom_flow(color = "darkgray") +
  geom_stratum() +
  theme(legend.position = "top") +
  labs(x = "2-Week Intervals", y = "Users", title = "Mode show_coins across 2-Week Intervals", legend = "Mode show_coins")
```

Zooming into this year and changing to weekly.

```{r}
# Getting data needed for sankey plot
sankey_data <- ed_logs %>%
  select(user_id, show_coins, time_weeks, date) %>%
  filter(user_id %in% swappers,
         time_weeks > 52) %>%
  mutate(interval = cut(time_weeks, breaks = seq(0, max(time_weeks), by = 2), labels = FALSE)) %>%
  group_by(interval) %>%
  mutate(start_date = as.character(min(as.Date(date)))) %>%  # Assign the earliest date in the interval
  ungroup()


# Group by individual and interval, then summarize
sankey_tibble <- sankey_data %>%
  group_by(user_id, interval, start_date) %>%
  summarize(mode_show_coins = names(which.max(table(show_coins)))) %>%
  ungroup()

# Make the plot
coins_sankey <- sankey_tibble %>%
ggplot(aes(x = start_date, stratum = mode_show_coins, alluvium = user_id, fill = mode_show_coins, label = mode_show_coins)) +
  theme_minimal() +
  geom_flow(color = "darkgray") +
  geom_stratum() +
  custom_theme +
  labs(x = "Interval Start Date", y = "Users", title = "Most Often Coin Showing Choice in 2-week Intervals", legend = "Mode show_coins")

coins_sankey
ggsave("Jan Group/Plots/Show_coins_Sankey.jpeg")

```


Between section 30 and 31 is when the change is made. Which happens to also be paired by a major exodus of students from not showing to then showing, meaning that at least to some extent communication of the feature has occurred outside of personal experience.

```{r}
# Looking deeper. Investigating if students who've never shown coins between sep 1st 2024 and oct 25th 2024 are part of that exodus
stuff <- ed_logs %>%
  select(user_id, show_coins, time_weeks, date) %>%
  filter(user_id %in% swappers, 
         time_weeks %in% 52:64) %>%
  arrange(user_id, time_weeks)

# Users who never showed coins in section 30 where change occurs
unknowners <- stuff %>%
  filter(time_weeks %in% 52:60) %>%    # Keep only rows within the specified weeks
  group_by(user_id) %>%                   # Group by user
  filter(all(show_coins == 0)) %>%        # Keep only users with all 0s across the weeks
  distinct(user_id) %>%
  pull(user_id)

# Users who used coins directly after the change
coiners <- stuff %>%
  group_by(user_id, time_weeks) %>%
  filter(time_weeks %in% 61:62 & any(show_coins == 1)) %>%
  distinct(user_id) %>% 
  pull(user_id)

# Users who went from never showing to showing after the change
enlightened <- stuff %>%
  filter(user_id %in% unknowners & user_id %in% coiners) %>%
  distinct(user_id) %>%
  pull(user_id)

# Proportion of users who went from not showing coins at all before the change, to showing after change
length(enlightened) / length(unknowners) # 0.6403509

```

With over about 64% of users who weren't showing coins changing to showing coins after the change, and showing coins is the only way to see if you're going into extended time, this provides some evidence that communication between students about the extended deadline is likely. However! this could also just be due to students curious about if what changes have been made to the coin animation.

If they now show coins more often than not this could be a sign that it is not initial curiosity, since the coin animation hasn't really changed, but rather is being used as a tool for checking the time, which is evidence of it being knowledge they gained from other students.

```{r}
# Do they show coins more than 1 session
# Count of show_coin setting for never showers who became showers after the change 
show_count <- stuff %>%
  filter(user_id %in% enlightened, time_weeks > 60) %>%
  group_by(user_id, show_coins) %>%
  summarize(count = n(), .groups = "drop") 

# Line chart ordered by proportion of showing coins
coins_plot <- show_count %>%
  group_by(user_id) %>%
  mutate(total = sum(count),                         
    prop = sum(count[show_coins == 1]) / total 
  ) %>%
  ungroup() %>%
  mutate(user_id = reorder(user_id, -total, mean)) %>%
  mutate(user_id = reorder(user_id, -prop, mean)) %>% # Reorder by proportion
ggplot(aes(x = user_id, y = count, color = factor(show_coins), group = show_coins)) +
  geom_line() +
  scale_color_manual(values = c("1" = "#00bfc4", "0" = "#f8766d"),
                     labels = c("Not Showing", "Showing"),
                     name = "Coins") +
  labs(title = "User Coin Showing Behavior", subtitle = "Ordered by Proportion of Coins Showing & Total Played", x = "Users", y = "Count") +
  custom_theme +
  theme(axis.text.x = element_blank())

coins_plot
ggsave("Jan Group/Plots/Coin Showing.jpeg")


```

We see that the majority of those who switched coins on, most of the time kept coins on which is a substantial change from their previous behavior.


```{r}
# Change in difficulty selection data
# Getting data needed for sankey plot
sankey_data <- ed_logs %>%
  select(user_id, difficulty, time_weeks, date) %>%
  filter(time_weeks > 52) %>%
  mutate(interval = cut(time_weeks, breaks = seq(0, max(time_weeks), by = 2), labels = FALSE)) %>%
  group_by(interval) %>%
  mutate(start_date = min(as.Date(date))) %>%  # Assign the earliest date in the interval
  ungroup()

sankey_data <- sankey_data %>%
  mutate(difficulty = factor(
    difficulty,
    levels = c(0, 1, 2),
    labels = c("Easy", "Medium", "Hard")))

# Group by individual and interval, then summarize
sankey_tibble <- sankey_data %>%
  group_by(user_id, interval, start_date) %>%
  summarize(Mode_difficulty = names(which.max(table(difficulty)))) %>%
  ungroup() %>%
  mutate(start_date = as.character(start_date))
  

color_scheme2 <- c(
  "Easy" = "#008856",
  "Medium" = "#0067A5",
  "Hard" = "#BE0032"
)

```


```{r}
# Change in difficulty selection plot
# Make the sankey plot
dif_sankey <- sankey_tibble %>%
ggplot(aes(x = start_date, stratum = Mode_difficulty, alluvium = user_id, fill = Mode_difficulty, label = Mode_difficulty)) +
  scale_fill_manual(values = color_scheme2) +
  geom_flow(color = "darkgray") +
  geom_stratum() +
  custom_theme +
  labs(x = "Interval Start Date", y = "Users", title = "Most Often Difficulty Chosen across 2-Week Intervals", legend = "Mode Difficulty")

dif_sankey
ggsave("Jan Group/Plots/Mode Difficulty Sankey.jpeg")

```


A large initial migration to medium difficulty on the day of the change. A surprising amount from hard, and an understandable amount from easy. Curiously, after the initial migration there is a consistent move back to hard difficulty for some. The amount of students in easy is noticeably lower after the change. 
Do these students who have left easy use the extended deadline?

```{r}
# Extended deadline/difficulty data
ed_diff_data <- ed_logs %>%
  select(user_id, difficulty, time_weeks, late_response, answer) %>%
  mutate(interval = cut(time_weeks, breaks = seq(0, max(time_weeks), by = 2), labels = FALSE),
         difficulty = factor(difficulty,
                             levels = c(0, 1, 2),
                             labels = c("Easy", "Medium", "Hard"))) %>%
  filter(interval > 29)

ed_diff_tibble <- ed_diff_data %>%
  group_by(user_id, interval) %>%
  summarize(mode_difficulty = names(which.max(table(difficulty))),
            extended_deadline_total = sum(late_response == 1 & answer != "…"),
            non_response_total = sum(answer == "…")) %>%
  ungroup()

```


```{r}
# Getting data for graphing response type and switch type
# Interaction of leaving easy and extended deadline
braves_all <- ed_diff_tibble %>%
  group_by(user_id) %>%
  mutate(first_cat = first(mode_difficulty), 
         switched = mode_difficulty != first_cat & interval > 1)

# Grouping and labeling based on switching and starting choices
suppressWarnings(switch_tracking_all <- braves_all %>% # Gives a false warning about inf
  group_by(user_id) %>%
  mutate(first_switch_week = if_else(switched, interval, NA_integer_), # Week of switch
    first_switch_week = case_when(any(switched) ~ min(first_switch_week, na.rm = TRUE),
                                  TRUE ~ NA_integer_),# Get the earliest switch
    stay_switched = if_else(                           # Check if they stay switched
      interval >= first_switch_week & switched, 
      mode_difficulty, 
      NA_character_
    )
  )) 
# Groups labeled and response types counted
stayers_all <- switch_tracking_all %>%
  summarise(
    switch_category = case_when(
      all(na.omit(switched) == first(na.omit(switched))) ~ "Never Switched",
      first(na.omit(switched)) == last(na.omit(switched)) ~ "Did Not Stay Switched",
      TRUE ~ "Stayed Switched"
    ),
    first_cat = first(mode_difficulty)
  ) %>%
  ungroup()

stayers_all <- switch_tracking_all %>%
  summarise(
    stayed_switched = case_when(
      # Never switched: all intervals are NA or the same as the first non-NA value
      all(na.omit(switched) == first(na.omit(switched))) & first(first_cat) == "Easy" ~ "Never Switched - Easy",
      all(na.omit(switched) == first(na.omit(switched))) & first(first_cat) == "Medium" ~ "Never Switched - Medium",
      all(na.omit(switched) == first(na.omit(switched))) & first(first_cat) == "Hard" ~ "Never Switched - Hard",
      # Did Not Stay Switched: First and last are the same but switched at some point
      first(na.omit(switched)) == last(na.omit(switched)) & first(first_cat) == "Easy" ~ "Did Not Stay Switched - Easy",
      first(na.omit(switched)) == last(na.omit(switched)) & first(first_cat) == "Medium" ~ "Did Not Stay Switched - Medium",
      first(na.omit(switched)) == last(na.omit(switched)) & first(first_cat) == "Hard" ~ "Did Not Stay Switched - Hard",
      # Stayed Switched: First and last are different
      first(first_cat) == "Easy" ~ "Stayed Switched - Easy",
      first(first_cat) == "Medium" ~ "Stayed Switched - Medium",
      first(first_cat) == "Hard" ~ "Stayed Switched - Hard",
      # Default case (in case of unexpected values)
      TRUE ~ "Unknown"
    )
  ) %>%
  ungroup()

# Joining switch labels and ed_logs relevant stuff
fgb_data <- ed_logs %>%
  select(user_id, difficulty, time_weeks, late_response, answer, date) %>%
  mutate(interval = cut(time_weeks, breaks = seq(0, max(time_weeks), by = 2), labels = FALSE),
         difficulty = factor(difficulty,
                             levels = c(0, 1, 2),
                             labels = c("Easy", "Medium", "Hard"))) %>%
  group_by(user_id, interval) %>%
  summarize(mode_difficulty = names(which.max(table(difficulty))),
            extended_deadline_total = sum(late_response == 1 & answer != "…"),
            non_response_before = sum(answer == "…" & date < change_date, na.rm = TRUE),
            non_response_after = sum(answer == "…" & date >= change_date, na.rm = TRUE),
            .groups = "drop")

  
collapsed_fgb <- fgb_data %>%
  group_by(user_id) %>%
  summarize(
    extended_deadline_total = sum(extended_deadline_total, na.rm = TRUE),
    non_response_before = sum(non_response_before, na.rm = TRUE),
    non_response_after = sum(non_response_after, na.rm = TRUE)
  ) %>%
  left_join(stayers_all, by = "user_id") %>%
  filter(!is.na(stayed_switched))


collapsed_long <- collapsed_fgb %>%
  pivot_longer(cols = c(extended_deadline_total, non_response_before, non_response_after),
               names_to = "response_type",
               values_to = "value"
  ) %>%
  mutate(stayed_switched = factor(stayed_switched, 
                                  levels = c("Did Not Stay Switched - Easy", "Did Not Stay Switched - Medium", "Did Not Stay Switched - Hard", "Stayed Switched - Easy", "Stayed Switched - Medium", "Stayed Switched - Hard", "Never Switched - Easy", "Never Switched - Medium", "Never Switched - Hard"))
  )
```


```{r}
# All combined
# Setting Color Scheme
response_color <- c(
  "extended_deadline_total" = "#E69F00",
  "non_response_before" = "#56B4E9",
  "non_response_after" = "#009E73"
)

# Faceted bar graph
full_plot <- ggplot(collapsed_long, aes(x = response_type, y = value, fill = response_type)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = response_color) +
  labs(
    title = "Response Type Totals",
    x = "Response Type",
    y = "Total Responses",
    fill = "Response Type"
  ) +
  custom_theme +
  theme(
    strip.text = element_text(size = 12),
    legend.position = "bottom",
    axis.title.x = element_blank(),
    axis.text.x = element_blank()
  ) 

full_plot
ggsave("Jan Group/Plots/Response Totals.jpeg")
```


```{r}
# Time to graph it
# Setting Color Scheme
response_color <- c(
  "extended_deadline_total" = "#E69F00",
  "non_response_before" = "#56B4E9",
  "non_response_after" = "#009E73"
)

# Faceted bar graph
fb_plot <- ggplot(collapsed_long, aes(x = response_type, y = value, fill = response_type)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = response_color) +
  labs(
    title = "Response Totals by Difficulty Switching Category",
    x = "Response Type",
    y = "Total Responses",
    fill = "Response Type"
  ) +
  custom_theme +
  facet_wrap(~ stayed_switched) +
  theme(
    strip.text = element_text(size = 12),
    legend.position = "bottom",
    axis.title.x = element_blank(),
    axis.text.x = element_blank()
  ) 

fb_plot
ggsave("Jan Group/Plots/Response totals by Difficulty.jpeg")

```


### Motivation

how many rage quits after non-answer before vs how many rq after late response and/or non-answer after. soft quits after late response, vs non_response. Use Threshold modelling (psych) for measuring build up and response w/ and w/out for quitting.

```{r}
# Of note, domain 5 is the only to not have 10/session but 15
# Data for motivation analysis: soft-quit, hard-quit, sessions per instance
motivation_data <- ed_logs %>%
  select(user_id, answer, date, new_user_domain_session_count, correct_answered, grade, domain_id, deadline, late_response, session, response_in_seconds) %>%
  rename(session_number = new_user_domain_session_count) %>%
  # Getting users who have before and after data and just this school year
  mutate(change = if_else(date < change_date, "Before", "After")) %>%
  filter(date > as.Date("2024-09-02") & any(change == "After")) %>%
  # For calculating hard quitting
  arrange(user_id, date) %>%
  mutate(
    time_diff = as.numeric(difftime(date, lag(date, default = first(date)), units = "mins")),
    play_sesh = cumsum(ifelse(is.na(time_diff) | time_diff > 30, 1, 0))
  ) %>%
  # Make hard quitting tracker
  group_by(user_id, play_sesh) %>%
  mutate(
    hard_quit = if_else(lead(play_sesh, default = first(play_sesh)) != play_sesh | is.na(lead(play_sesh)), TRUE, FALSE)
  ) %>%
  ungroup() %>%
  select(-time_diff)

# Keeping track of soft-quitting and afk in session
softies <- motivation_data %>%
  select(user_id, domain_id, session_number, play_sesh, session) %>%
  mutate(full = if_else(domain_id == 5, 15, 10)) %>%
  group_by(user_id, domain_id, session_number, play_sesh, session, full) %>%
  summarise(count = n(),
            soft_quit = case_when(all(count != full & session == "domain") ~ TRUE,
                           all(count == full & session == "domain") ~ FALSE,
                           all(count %% full != 0 & session == "learning_goal") ~ TRUE,
                           all(count %% full == 0 & session == "learning_goal") ~ FALSE,
                           TRUE ~ NA),
            .groups = "drop") %>%
  select(-count, -full)


# Merging soft-quit into motivation data
motivation_data <- motivation_data %>%
  left_join(softies) %>%
  mutate(response_timing = case_when(late_response == 1 & answer != "…" ~ "extended",
                                     answer == "…" & date < change_date ~ "non_response_before",
                                     answer == "…" & date >= change_date ~ "non_response_after",
                                     TRUE ~ "on_time"))

# Calculating if session had likely afk
afking <- motivation_data %>%
  group_by(user_id, domain_id, session_number, play_sesh, session) %>%
  summarise(afk = any(rle(answer == "…")$values & rle(answer == "…")$lengths >= 3))
  
# Merging back into motivation_data
motivation_data <- motivation_data %>%
  left_join(afking) %>%
  mutate(change = factor(change, levels = c("Before", "After")))
```

```{r}
# Making the visualizations
# Color Pallette
before_after_color <- c("Before" = "#00bfc4",
                  "After" = "#f8766d")

# Plotting percent of soft quitting and afking before and after change
afk_sq_plot <- motivation_data %>%
  group_by(change) %>%
  summarise(
    soft_quitting_count = sum(soft_quit),      
    afking_count = sum(afk),                  
    soft_quitting = soft_quitting_count / n() * 100,  
    afking = afking_count / n() * 100,       
    .groups = "drop"
  ) %>%
  pivot_longer(
    cols = c(soft_quitting, afking),
    names_to = "quit_type",
    values_to = "value"
  ) %>%
  pivot_longer(
    cols = c(soft_quitting_count, afking_count),
    names_to = "quit_type_count",
    values_to = "count",
    names_transform = list(quit_type_count = ~ gsub("_count", "", .x)) # Clean names
  ) %>%
  filter(quit_type == quit_type_count) %>% # Match percentage and counts
  ggplot(aes(x = quit_type, y = value, fill = change)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(
    aes(label = count, group = change),
    position = position_dodge(width = 0.9),
    vjust = -0.5
  ) +
  scale_fill_manual(values = before_after_color) +
  scale_y_continuous(labels = label_percent(scale = 1)) + # Format y-axis as percentages
  labs(
    title = "Problem Quitting Percentages Before and After UI Change",
    x = "Quitting Type",
    y = "Percent of Responses",
    fill = "Timing"
  ) +
  custom_theme

afk_sq_plot
ggsave("Jan Group/Plots/Soft Quitting and AFK.jpeg")

```


How much of hard quitting had a soft quit before it vs a complete session, before and after the change?

```{r}
# Color Pallet
soft_complete_color <- c("completed_session" = "#00bfc4",
                  "soft_quitting" = "#f8766d")

# Plotting percent of hard quits after soft-quit vs completed session
pie <- motivation_data %>%
  filter(hard_quit == TRUE) %>%
  group_by(change) %>%
  summarise(
    soft_quitting_count = sum(soft_quit),      
    completed_session_count = sum(!soft_quit),          
    soft_quitting = soft_quitting_count / n() * 100,  
    completed_session = completed_session_count / n() * 100,  
    .groups = "drop"
  ) %>%
  pivot_longer(
    cols = c(soft_quitting, completed_session),
    names_to = "quit_type",
    values_to = "value"
  ) %>%
  pivot_longer(
    cols = c(soft_quitting_count, completed_session_count),
    names_to = "quit_type_count",
    values_to = "count",
    names_transform = list(quit_type_count = ~ gsub("_count", "", .x))  # Clean names
  ) %>%
  filter(quit_type == quit_type_count) %>%  # Match percentage and counts
  ggplot(aes(x = "", y = value, fill = quit_type)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +  # Convert to pie chart
  facet_wrap(~ change) +  # Facet by 'before' or 'after'
  geom_text(
    aes(label = paste0(quit_type, "\n", round(value, 1), "%\n", count)), 
    position = position_stack(vjust = 0.5)
  ) +
  scale_fill_manual(values = soft_complete_color) +
  labs(
    title = "Application Closed After Quitting a Session Early",
    x = NULL, y = NULL,
    fill = "Quit Type"
  ) +
  theme_void() +  # Use theme_void to remove axis and grid lines for pie charts
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    strip.text = element_text(size = 12),
    legend.position = "none"
  )

pie
ggsave("Jan Group/Plots/Hard Quit: Soft vs Complete.jpeg")

```


Cox Proportional Hazards Model to check if extended_deadline use has an increased probability of continuing to play.


```{r}
# Function to plot the different survival curves
surv_plotter <- function(surv_fit_grouped, groups = c("No Extension Used", "Extension Used"), title_specification, xlimit){

# Color Pallet
custom_color <- c("#f8766d", "#00bfc4")

# Convert summary to dataframe
surv_df_grouped <- data.frame(
  time = surv_fit_grouped$time,
  surv_0 = surv_fit_grouped$surv[, 1],  
  surv_1 = surv_fit_grouped$surv[, 2],  
  lower_0 = surv_fit_grouped$lower[, 1],  
  lower_1 = surv_fit_grouped$lower[, 2],  
  upper_0 = surv_fit_grouped$upper[, 1],  
  upper_1 = surv_fit_grouped$upper[, 2]   
)

# Pivot to long format
plot <- surv_df_grouped %>%
  pivot_longer(cols = -time, 
               names_to = c(".value", "Group"),
               names_sep = "_") %>%
  mutate(Group = factor(Group, levels = c("0", "1"), labels = groups)) %>%


# Plot grouped Cox-Adjusted Kaplan-Meier curves
ggplot(aes(x = time, y = surv, color = Group)) +
  scale_color_manual(values = custom_color) +
  geom_step() +
  xlim(0, xlimit) +
  geom_ribbon(aes(ymin = lower, ymax = upper, fill = Group), alpha = 0.2) +
  labs(x = "Time (seconds)",
       y = "Survival Probability", 
       title = "Cox-Adjusted Survival Curves",
       subtitle = title_specification) +
  custom_theme 

return(plot)
}
```


```{r}
# Creating data for soft_quitting survival checking
cox_data_soft <- motivation_data %>%
  # Because time format was refusing to work
  mutate(seconds_since_midnight = hour(date) * 3600 + minute(date) * 60 + second(date)) %>%
  group_by(user_id, play_sesh, session_number, domain_id, session) %>%
  summarise(duration = ifelse(n() > 1, # Some times only 1 item played
                       as.integer(max(seconds_since_midnight) - min(seconds_since_midnight)), 
                       as.integer(response_in_seconds)),
            extended_deadline_used = any(response_timing == "extended"),
            soft_quit = any(soft_quit),
            hard_quit = any(hard_quit),
            change = first(change),
            .groups = "drop"
  )

```

Duration could use further investigation, considering there are some sessions with extreme durations, could be interesting for checking for afks. A decent amount have soft_quit and/or hard_quit true (eyeballing it seems like if soft_quit is true then hard_quit usually is) but plenty don't. Interesting.

```{r}
# Creating data for hard_quitting survival checking
cox_data_hard <- motivation_data %>%
  mutate(seconds_since_midnight = hour(date) * 3600 + minute(date) * 60 + second(date)) %>%
  group_by(user_id, play_sesh) %>%
  summarise(
    duration = ifelse(n() > 1, 
                      as.integer(max(seconds_since_midnight) - min(seconds_since_midnight)), 
                       as.integer(response_in_seconds)),
    extended_deadline_used = any(response_timing == "extended"),
    soft_quit = any(soft_quit),
    hard_quit = any(hard_quit),
    change = first(change),
    .groups = "drop"
  )
```

Duration is interesting yet again, but for a different reason. It turns out that there seems to be a surprising amount of application runs that only consist of performing a single item and then quitting completely. Interesting for future investigation possibly.




```{r, warning=FALSE}
# Cox model to determine survival probability on session length
cox_model_soft <- coxph(Surv(duration, soft_quit) ~ extended_deadline_used, data = cox_data_soft)

# Model fitting for plotting
cox_fit_soft <- survfit(cox_model_soft, newdata = data.frame(extended_deadline_used = c(0, 1)))

# Plot it
se_plot <- surv_plotter(cox_fit_soft, title_specification = ("Extended Duration and Mid-Session Quitting"), xlimit = 5000)

se_plot
ggsave("Jan Group/Plots/Soft Quitting Cox-Curve: Extended Duration.jpeg")

```

What about if we only include since the UI change?

```{r, warning=FALSE}
# Filtered data
cox_data_soft_after <- cox_data_soft %>%
  filter(change == "After")
# Cox model to determine survival probability on session length
cox_model_soft_after <- coxph(Surv(duration, soft_quit) ~ extended_deadline_used, data = cox_data_soft_after)

# Model fitting for plotting
cox_fit_soft_after <- survfit(cox_model_soft_after, newdata = data.frame(extended_deadline_used = c(0, 1)))

# Plot it
se_after_plot <- surv_plotter(cox_fit_soft_after, title_specification = ("Extended Duration and Mid-Session Quitting: After"), xlimit = 5000)

se_after_plot
ggsave("Jan Group/Plots/Soft Quitting Cox-Curve: Extended Duration only After.jpeg")

```

It appears that the main difference is just the increased confidence intervals due to having less data. This is very promising evidence that the extended deadline is helping students stick with their sessions.


```{r, warning=FALSE}
# Cox model to determine survival probability on session length
cox_model_hard <- coxph(Surv(duration, hard_quit) ~ extended_deadline_used, data = cox_data_hard)

# Model fitting for plotting
cox_fit_hard <- survfit(cox_model_hard, newdata = data.frame(extended_deadline_used = c(0, 1)))

# Plot it
he_plot <- surv_plotter(cox_fit_hard, title_specification = ("Extended Duration and Application Quitting"), xlimit = 5000)

he_plot
ggsave("Jan Group/Plots/Hard Quitting Cox-Curve: Extended Duration.jpeg")

```

```{r, warning=FALSE}
# Filtered data
cox_data_hard_after <- cox_data_hard %>%
  filter(change == "After")
# Cox model to determine survival probability on session length
cox_model_hard_after <- coxph(Surv(duration, hard_quit) ~ extended_deadline_used, data = cox_data_hard_after)

# Model fitting for plotting
cox_fit_hard_after <- survfit(cox_model_hard_after, newdata = data.frame(extended_deadline_used = c(0, 1)))

# Plot it
he_after_plot <- surv_plotter(cox_fit_hard_after, title_specification = ("Extended Duration and Application Quitting: After"), xlimit = 5000)

he_after_plot
ggsave("Jan Group/Plots/Hard Quitting Cox-Curve: Extended Duration only After.jpeg")

```

It is only slightly, however, the gap between using the extended deadline and not has actually increased, with extended increasing in survival chance and non-extended use decreasing in survival chance. Again, more evidence that it is a helpful intervention for motivating students to keep going. 


```{r}
# Testing with runs of at least 1 session played
# Creating data for hard_quitting survival checking
cox_data_hard_complete <- motivation_data %>%
  mutate(seconds_since_midnight = hour(date) * 3600 + minute(date) * 60 + second(date)) %>%
  group_by(user_id, play_sesh) %>%
  summarise(duration = ifelse(n() > 1, 
                              as.integer(max(seconds_since_midnight) - min(seconds_since_midnight)), 
                              response_in_seconds),
            extended_deadline_used = any(response_timing == "extended"),
            complete_session = any(soft_quit == FALSE),
            soft_quit = any(soft_quit),
            hard_quit = any(hard_quit),
            .groups = "drop"
  ) %>%
  filter(complete_session == TRUE)
```

Still quite a lot of application runs that are very short even when running at least 1 complete session. 

```{r, warning=FALSE}
# Cox model to determine survival probability on session length
cox_model_hard_complete <- coxph(Surv(duration, hard_quit) ~ extended_deadline_used, data = cox_data_hard_complete)

# Model fitting for plotting
cox_fit_hard_complete <- survfit(cox_model_hard_complete, newdata = data.frame(extended_deadline_used = c(0, 1)))

# Plot it
surv_plotter(cox_fit_hard_complete, groups = c("no extended", "extended"), title_specification = ("Extended Duration and Application Quitting: At Least 1"), xlimit = 5000)

```

Also doesn't seem to change the curve very much, only increasing the survival chance very slightly.


### DESCRIPTIVES

```{r}
# Check the structure and unique values in domain_id
str(ed_logs)
unique(ed_logs$domain_id)

# Add a new variable indicating whether the response was late
# late_response: 1 indicates late response, 0 indicates on-time response
ed_logs <- ed_logs %>%
  mutate(late_response = ifelse(response_in_seconds > deadline, 1, 0))

# Show the earliest and latest date in the dataset
earliest_date <- min(ed_logs$date, na.rm = TRUE)
latest_date <- max(ed_logs$date, na.rm = TRUE)
print(paste("Earliest date:", earliest_date))
print(paste("Latest date:", latest_date))

# Split the data into before and after October 25, 2024
split_date <- as.Date("2024-10-25")
# Filter records after the split date
ed_logs_after <- ed_logs %>%
  filter(date > split_date)

# Count the occurrences of each value in the late_response column (only for after October 25, 2024)
# late_response: 1 = late, 0 = on-time
late_response_counts_after <- ed_logs_after %>%
  count(late_response) 

# Display late_response counts (after October 25, 2024)
print(late_response_counts_after) #244202 late

# Count unique users that provided late responses (in total)
unique_late_users_total <- ed_logs %>%
  filter(late_response == 1) %>%
  summarize(unique_users = n_distinct(user_id))
print(paste("Total unique users with late responses:", unique_late_users_total$unique_users)) # 18444

# Count unique users that provided late responses per domain
unique_late_users_by_domain <- ed_logs %>%
  filter(late_response == 1) %>%
  group_by(domain_id) %>%
  summarize(unique_users = n_distinct(user_id)) %>%
  arrange(desc(unique_users))

# Display the unique late users per domain
print(unique_late_users_by_domain) # 8453 for 59  

# Analysis for users who provided late responses
late_users <- ed_logs %>%
  filter(late_response == 1)

# Frequency of late responses after October 25, 2024, compared to all responses
late_response_frequency <- ed_logs_after %>%
  filter(user_id %in% late_users$user_id) %>%
  group_by(user_id) %>%
  summarize(
    late_responses_after = sum(late_response),
    total_responses_after = n(),
    late_response_rate_after = mean(late_response)
  )
print("Late response frequency after October 25, 2024:")
print(late_response_frequency) # difficult to summarize in one sentence but some kids indeed use it often


# Percentage of correct answers when responses are late per domain
# correct_answered: "1" = correct, "0" = incorrect
correct_answers_late <- late_users %>%
  group_by(domain_id) %>%
  summarize(
    total_late_responses = n(),
    correct_late_responses = sum(correct_answered == "1"),
    correct_percentage_late = mean(correct_answered == "1")
  )
print("Percentage of correct answers when responses are late per domain:")
print(correct_answers_late) # almost 60% of late answers in domain 5 and 59 are correct


# Calculate the proportion of late responses per domain
late_response_by_domain <- ed_logs %>%
  group_by(domain_id) %>%
  summarize(
    total_responses = n(),
    late_responses = sum(late_response),
    late_response_rate = mean(late_response)
  ) %>%
  arrange(desc(late_response_rate))

# Display the summary table
print(late_response_by_domain) # it's not much compared to total answers per domain yet but you can see a trend on which domains are more affected

# Visualize late response rates by domain
late_response_by_domain %>%
  ggplot(aes(x = fct_reorder(domain_id, late_response_rate), y = late_response_rate)) +
  geom_col() +
  coord_flip() +
  labs(
    title = "Late Response Rate by Domain",
    x = "Domain ID",
    y = "Late Response Rate"
  ) +
  theme_minimal()

# Analyze the relationship between difficulty and late responses
# difficulty: categorical variable indicating task difficulty level
# late_response: 1 = late, 0 = on-time
difficulty_analysis <- ed_logs %>%
  group_by(difficulty) %>%
  summarize(
    total_responses = n(),
    late_responses = sum(late_response),
    late_response_rate = mean(late_response)
  )

# Display the summary table
print(difficulty_analysis)

# Visualize late response rates by difficulty
difficulty_analysis %>%
  ggplot(aes(x = difficulty, y = late_response_rate)) +
  geom_col(fill = "steelblue") +
  labs(
    title = "Late Response Rate by Difficulty Level",
    x = "Difficulty Level",
    y = "Late Response Rate"
  ) +
  theme_minimal()

# Explore the trend of late responses over time (weekly)
late_response_time_trend <- ed_logs %>%
  mutate(week = lubridate::floor_date(date, "week")) %>%
  group_by(week) %>%
  summarize(
    total_responses = n(),
    late_responses = sum(late_response),
    late_response_rate = mean(late_response)
  )

# Visualize the trend
late_response_time_trend %>%
  ggplot(aes(x = week, y = late_response_rate)) +
  geom_line(color = "blue") +
  labs(
    title = "Trend of Late Responses Over Time",
    x = "Week",
    y = "Late Response Rate"
  ) +
  theme_minimal()

# Temporal Patterns
# Late Response by Hour of Day
# hour: extracted from the timestamp to analyze time-based patterns
late_response_by_hour <- ed_logs %>%
  mutate(hour = hour(date)) %>%
  group_by(hour) %>%
  summarize(
    total_responses = n(),
    late_responses = sum(late_response),
    late_response_rate = mean(late_response)
  )
print("Late Response Rate by Hour of Day:")
print(late_response_by_hour)

late_response_by_hour %>%
  ggplot(aes(x = hour, y = late_response_rate)) +
  geom_line() +
  labs(
    title = "Late Response Rate by Hour of Day",
    x = "Hour of Day",
    y = "Late Response Rate"
  ) +
  theme_minimal()

# Late Response by Day of the Week
# weekday: extracted as a categorical label for days of the week
late_response_by_day <- ed_logs %>%
  mutate(weekday = wday(date, label = TRUE)) %>%
  group_by(weekday) %>%
  summarize(
    total_responses = n(),
    late_responses = sum(late_response),
    late_response_rate = mean(late_response)
  )
print("Late Response Rate by Day of the Week:")
print(late_response_by_day)

late_response_by_day %>%
  ggplot(aes(x = weekday, y = late_response_rate)) +
  geom_col(fill = "skyblue") +
  labs(
    title = "Late Response Rate by Day of the Week",
    x = "Day of the Week",
    y = "Late Response Rate"
  ) +
  theme_minimal()

# Behavioral Patterns: Consecutive Late Responses
# streak: counts consecutive late responses for each user
consecutive_late_responses <- ed_logs %>%
  arrange(user_id, date) %>%
  group_by(user_id) %>%
  mutate(streak = cumsum(c(0, diff(late_response)) > 0)) %>%
  filter(late_response == 1) %>%
  summarize(max_streak = max(streak))
print("Max Consecutive Late Responses by User:")
print(consecutive_late_responses)

# Impact of Late Responses: Time Spent
# Analyze average and total time spent based on response timeliness
impact_time_spent <- ed_logs %>%
  group_by(late_response) %>%
  summarize(
    avg_time_spent = mean(response_in_seconds, na.rm = TRUE),
    total_time_spent = sum(response_in_seconds, na.rm = TRUE)
  )
print("Average and Total Time Spent by Late Response:")
print(impact_time_spent)

# Engagement Over Time
# session_week: groups responses by week for trend analysis
engagement_trend <- ed_logs %>%
  mutate(session_week = floor_date(date, "week")) %>%
  group_by(session_week, late_response) %>%
  summarize(total_responses = n()) %>%
  spread(late_response, total_responses, fill = 0)
print("Engagement Trend Over Time by Late Response:")
print(engagement_trend)

# Domain-Specific Analysis with Difficulty Interaction
# Analyze interaction between domain_id and difficulty for late responses
late_response_by_domain_difficulty <- ed_logs %>%
  group_by(domain_id, difficulty) %>%
  summarize(
    total_responses = n(),
    late_responses = sum(late_response),
    late_response_rate = mean(late_response)
  )
print("Late Response Rate by Domain and Difficulty:")
print(late_response_by_domain_difficulty)

late_response_by_domain_difficulty %>%
  ggplot(aes(x = difficulty, y = late_response_rate, fill = domain_id)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Late Response Rate by Domain and Difficulty",
    x = "Difficulty",
    y = "Late Response Rate"
  ) +
  theme_minimal()

```

```{r}
# Percent of late responses that went past extended
sum(ed_logs_after$answer == "…")/sum(ed_logs_after$late_response == 1) * 100 # 23.92%
```






```{r}
oefenwebDatabase::close_connection(con)
```

